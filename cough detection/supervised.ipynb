{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('sup_loaded_data_1000.pickle', 'rb') as f:\n",
    "    sup_DATA = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('sup_loaded_data_2000.pickle', 'rb') as f:\n",
    "    sup_DATA = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1989"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sup_DATA[1]['MEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import Sequential,Model\n",
    "from keras.layers import concatenate,Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import roc_curve\n",
    "from keras.utils import np_utils\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa \n",
    "import librosa.display\n",
    "import pylab\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self,imgfiles,labels,batch_size,target_size=(64,64),shuffle=False,scale=255,n_classes=1,n_channels=3):\n",
    "        self.batch_size = batch_size\n",
    "        self.dim        = target_size\n",
    "        self.labels     = labels\n",
    "        self.imgfiles   = imgfiles\n",
    "        self.n_classes  = n_classes\n",
    "        self.shuffle    = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.scale      = scale\n",
    "        self.c          = 0\n",
    "        self.on_epoch_end() \n",
    "\n",
    "    def __len__(self):\n",
    "        # returns the number of batches\n",
    "        return int(np.floor(len(self.imgfiles) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns one batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.imgfiles))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            img   = cv2.imread(self.imgfiles[ID])\n",
    "            img   = cv2.resize(img,self.dim,interpolation = cv2.INTER_CUBIC)\n",
    "#             img = np.log(img + 1e-9)\n",
    "#             img = librosa.util.normalize(img)\n",
    "            X[i,] = img / self.scale\n",
    "            X[i,] = img \n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "            self.c +=1\n",
    "        return X, y #keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "\n",
    "\n",
    "class CustomPipeline(tf.keras.utils.Sequence):\n",
    "    def __init__(self,data_x,data_y,batch_size=48,shuffle=False,n_classes=1):\n",
    "        self.features   = data_x\n",
    "        self.labels     = data_y\n",
    "        self.batch_size = 48\n",
    "        self.shuffle    = shuffle\n",
    "        self.n_features = self.features.shape[1]\n",
    "        self.n_classes  = 1\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return int(np.floor(len(self.features) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X, y = self.__data_generation(indexes)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.features))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    " \n",
    "    def __data_generation(self,indexes):\n",
    "        X = np.empty((self.batch_size, self.n_features))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        for i, ID in enumerate(indexes):\n",
    "            X[i,] = self.features[ID]\n",
    "            y[i,] = self.labels[ID]\n",
    "        return X, y\n",
    "    \n",
    "class specGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Wrapper of two generatos for the combined input model\"\"\"\n",
    "\n",
    "    def __init__(self, X2, Y, batch_size,target_size=(64,64)):\n",
    "        self.genX2 = CustomDataset(X2, Y, batch_size=batch_size,shuffle=False,target_size=target_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.genX2.__len__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_batch, Y_batch = self.genX2.__getitem__(index)\n",
    "        return X_batch, Y_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset_1D(tf.keras.utils.Sequence):\n",
    "    def __init__(self,imgfiles,labels,batch_size,target_size=(64,64),shuffle=False,scale=255,n_classes=1,n_channels=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.dim        = target_size\n",
    "        self.labels     = labels\n",
    "        self.imgfiles   = imgfiles\n",
    "        self.n_classes  = n_classes\n",
    "        self.shuffle    = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.scale      = scale\n",
    "        self.c          = 0\n",
    "        self.on_epoch_end() \n",
    "\n",
    "    def __len__(self):\n",
    "        # returns the number of batches\n",
    "        return int(np.floor(len(self.imgfiles) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns one batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.imgfiles))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            img   = cv2.imread(self.imgfiles[ID])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img   = cv2.resize(img,self.dim,interpolation = cv2.INTER_CUBIC)\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "#             img   = cv2.resize(img,self.dim,interpolation = cv2.INTER_CUBIC)\n",
    "#             img = np.log(img + 1e-9)\n",
    "#             img = librosa.util.normalize(img)\n",
    "            X[i,] = img / self.scale\n",
    "            X[i,] = img \n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "            self.c +=1\n",
    "        return X, y #keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "\n",
    "\n",
    "class CustomPipeline_1D(tf.keras.utils.Sequence):\n",
    "    def __init__(self,data_x,data_y,batch_size=48,shuffle=False,n_classes=1):\n",
    "        self.features   = data_x\n",
    "        self.labels     = data_y\n",
    "        self.batch_size = 48\n",
    "        self.shuffle    = shuffle\n",
    "        self.n_features = self.features.shape[1]\n",
    "        self.n_classes  = 1\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return int(np.floor(len(self.features) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X, y = self.__data_generation(indexes)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.features))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    " \n",
    "    def __data_generation(self,indexes):\n",
    "        X = np.empty((self.batch_size, self.n_features))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        for i, ID in enumerate(indexes):\n",
    "            X[i,] = self.features[ID]\n",
    "            y[i,] = self.labels[ID]\n",
    "        return X, y\n",
    "    \n",
    "class specGenerator_1D(keras.utils.Sequence):\n",
    "    \"\"\"Wrapper of two generatos for the combined input model\"\"\"\n",
    "\n",
    "    def __init__(self, X2, Y, batch_size,target_size=(64,64)):\n",
    "        self.genX2 = CustomDataset_1D(X2, Y, batch_size=batch_size,shuffle=False,target_size=target_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.genX2.__len__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_batch, Y_batch = self.genX2.__getitem__(index)\n",
    "        return X_batch, Y_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class Evaluation(Callback):\n",
    "    def __init__(self, val_data_gen, val_labels, test_data_gen, test_labels):\n",
    "        super(Evaluation, self).__init__()\n",
    "        self.test_data = test_data_gen\n",
    "        self.val_labels = val_labels\n",
    "        self.val_data = val_data_gen\n",
    "        self.test_labels = test_labels\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_preds = self.model.predict_generator(self.val_data)\n",
    "        print(' | val_auc:', roc_auc_score(self.val_labels[:len(y_preds)], y_preds))\n",
    "\n",
    "        y_preds = self.model.predict_generator(self.test_data)\n",
    "        print(' | test_auc:', roc_auc_score(self.test_labels[:len(y_preds)], y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    '''Function to build ensemble model'''\n",
    "    # First Model\n",
    "    inp1   = Input(shape=39)\n",
    "    lay1   = Dense(units=512,activation='relu',kernel_initializer='GlorotUniform')(inp1)\n",
    "    lay2   = Dropout(0.4)(lay1)\n",
    "    lay3   = Dense(units=256,activation='relu',kernel_initializer='GlorotUniform')(lay2)\n",
    "    lay4   = Dropout(0.2)(lay3)\n",
    "\n",
    "    # Second Model\n",
    "    inp2   = Input(shape=(64,64,3))\n",
    "    lay1_  = Conv2D(32, (3, 3), strides=(2, 2))(inp2)\n",
    "    lay2_  = AveragePooling2D((2, 2), strides=(2,2))(lay1_)\n",
    "    lay3_  = BatchNormalization()(lay2_)\n",
    "    lay4_  = Activation('relu')(lay3_)\n",
    "\n",
    "    lay5_  = Conv2D(64, (3, 3), padding=\"same\") (lay4_)\n",
    "    lay6_  = AveragePooling2D((2, 2), strides=(2,2)) (lay5_)\n",
    "    lay7_  = BatchNormalization()(lay6_)\n",
    "    lay8_  = Activation('relu')(lay7_)\n",
    "\n",
    "    lay9_  = Conv2D(64, (3, 3), padding=\"same\") (lay8_)\n",
    "    lay10_ = AveragePooling2D((2, 2), strides=(2,2)) (lay9_)\n",
    "    lay11_ = BatchNormalization()(lay10_)\n",
    "    lay12_ = Activation('relu')(lay11_)\n",
    "\n",
    "    lay13_ = Flatten()(lay12_)\n",
    "    lay14_ = Dense(units=256,activation='relu',kernel_initializer='GlorotUniform')(lay13_)\n",
    "    lay15_ = Dropout(rate=0.3)(lay14_)\n",
    "    # Third model\n",
    "    inp3   = Input(shape=2)\n",
    "    lay31  = Dense(units=16,activation='relu',kernel_initializer='GlorotUniform')(inp3)\n",
    "    lay32  = Dropout(0.4)(lay31)\n",
    "    lay33  = Dense(units=64,activation='relu',kernel_initializer='GlorotUniform')(lay32)\n",
    "    lay43  = Dropout(0.2)(lay33)\n",
    "\n",
    "    # merge input models\n",
    "    merge = concatenate([lay15_, lay4,lay43])\n",
    "\n",
    "    # interpretation model\n",
    "    hidden1 = Dense(64, activation='relu')(merge)\n",
    "    hidden2 = Dense(64, activation='relu')(hidden1)\n",
    "    output  = Dense(1, activation='sigmoid')(lay15_)\n",
    "    MERGM   = Model(inputs=[inp2,inp3], outputs=output)\n",
    "\n",
    "    return MERGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_1D():\n",
    "    '''Function to build ensemble model'''\n",
    "    # First Model\n",
    "#     inp1   = Input(shape=39)\n",
    "#     lay1   = Dense(units=512,activation='relu',kernel_initializer='GlorotUniform')(inp1)\n",
    "#     lay2   = Dropout(0.4)(lay1)\n",
    "#     lay3   = Dense(units=256,activation='relu',kernel_initializer='GlorotUniform')(lay2)\n",
    "#     lay4   = Dropout(0.2)(lay3)\n",
    "\n",
    "    # Second Model\n",
    "    inp2   = Input(shape=(64,64,1))\n",
    "    lay1_  = Conv2D(64, (3, 3), strides=(2, 2))(inp2)\n",
    "    lay2_  = AveragePooling2D((2, 2), strides=(2,2))(lay1_)\n",
    "    lay3_  = BatchNormalization()(lay2_)\n",
    "    lay4_  = Activation('relu')(lay3_)\n",
    "\n",
    "    lay5_  = Conv2D(128, (3, 3), padding=\"same\") (lay4_)\n",
    "    lay6_  = AveragePooling2D((2, 2), strides=(2,2)) (lay5_)\n",
    "    lay7_  = BatchNormalization()(lay6_)\n",
    "    lay8_  = Activation('relu')(lay7_)\n",
    "\n",
    "    lay9_  = Conv2D(128, (3, 3), padding=\"same\") (lay8_)\n",
    "    lay10_ = AveragePooling2D((2, 2), strides=(2,2)) (lay9_)\n",
    "    lay11_ = BatchNormalization()(lay10_)\n",
    "    lay12_ = Activation('relu')(lay11_)\n",
    "\n",
    "    lay13_ = Flatten()(lay12_)\n",
    "    lay14_ = Dense(units=256,activation='relu',kernel_initializer='GlorotUniform')(lay13_)\n",
    "    lay15_ = Dropout(rate=0.5)(lay14_)\n",
    "\n",
    "    # Third model\n",
    "#     inp3   = Input(shape=2)\n",
    "#     lay31  = Dense(units=16,activation='relu',kernel_initializer='GlorotUniform')(inp3)\n",
    "#     lay32  = Dropout(0.4)(lay31)\n",
    "#     lay33  = Dense(units=64,activation='relu',kernel_initializer='GlorotUniform')(lay32)\n",
    "#     lay43  = Dropout(0.2)(lay33)\n",
    "\n",
    "    # merge input models\n",
    "#     merge = concatenate([lay4, lay43])\n",
    "\n",
    "    # interpretation model\n",
    "#     hidden1 = Dense(64, activation='relu')(merge)\n",
    "    # projection head\n",
    "    output  = Dense(1, activation='sigmoid')(lay15_)\n",
    "    MERGM   = Model(inputs=inp2, outputs=output)\n",
    "\n",
    "    return MERGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetSimCLR(base_model='resnet18'):\n",
    "    inputs = tf.keras.layers.Input(shape=(64,64,1))\n",
    "\n",
    "    base_encoder = tf.keras.applications.ResNet50(include_top=False, weights=None, input_tensor=None,\n",
    "                                                  input_shape=(64,64,1), pooling='avg')\n",
    "    base_encoder.training = True\n",
    "    h = base_encoder(inputs)\n",
    "\n",
    "    # projection head\n",
    "    x = tf.keras.layers.Dense(256)(h)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Dense(256)(x)\n",
    "    output  = Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " | val_auc: 0.7353896103896104\n",
      " | test_auc: 0.7484041216386027\n",
      "43/43 - 7s - loss: 0.6967 - auc: 0.6349 - val_loss: 0.6623 - val_auc: 0.7344\n",
      "Epoch 2/30\n",
      " | val_auc: 0.8137682629870131\n",
      " | test_auc: 0.8319929630560443\n",
      "43/43 - 7s - loss: 0.5510 - auc: 0.7787 - val_loss: 0.5952 - val_auc: 0.8147\n",
      "Epoch 3/30\n",
      " | val_auc: 0.8544034090909091\n",
      " | test_auc: 0.8723548630309123\n",
      "43/43 - 7s - loss: 0.4893 - auc: 0.8344 - val_loss: 0.5498 - val_auc: 0.8549\n",
      "Epoch 4/30\n",
      " | val_auc: 0.8846387987012987\n",
      " | test_auc: 0.9066850967579794\n",
      "43/43 - 7s - loss: 0.4542 - auc: 0.8649 - val_loss: 0.5077 - val_auc: 0.8848\n",
      "Epoch 5/30\n",
      " | val_auc: 0.8989448051948051\n",
      " | test_auc: 0.9208595124403116\n",
      "43/43 - 7s - loss: 0.4288 - auc: 0.8791 - val_loss: 0.4676 - val_auc: 0.8987\n",
      "Epoch 6/30\n",
      " | val_auc: 0.906351461038961\n",
      " | test_auc: 0.9265895953757225\n",
      "43/43 - 7s - loss: 0.3912 - auc: 0.9012 - val_loss: 0.4317 - val_auc: 0.9066\n",
      "Epoch 7/30\n",
      " | val_auc: 0.908887987012987\n",
      " | test_auc: 0.9294043729580296\n",
      "43/43 - 7s - loss: 0.3791 - auc: 0.9081 - val_loss: 0.4047 - val_auc: 0.9092\n",
      "Epoch 8/30\n",
      " | val_auc: 0.9112215909090907\n",
      " | test_auc: 0.9315154561447601\n",
      "43/43 - 7s - loss: 0.3816 - auc: 0.9053 - val_loss: 0.3873 - val_auc: 0.9110\n",
      "Epoch 9/30\n",
      " | val_auc: 0.9140624999999999\n",
      " | test_auc: 0.9335260115606936\n",
      "43/43 - 7s - loss: 0.3533 - auc: 0.9210 - val_loss: 0.3760 - val_auc: 0.9139\n",
      "Epoch 10/30\n",
      " | val_auc: 0.9129971590909091\n",
      " | test_auc: 0.9351847197788389\n",
      "43/43 - 6s - loss: 0.3472 - auc: 0.9234 - val_loss: 0.3695 - val_auc: 0.9131\n",
      "Epoch 11/30\n",
      " | val_auc: 0.9148741883116883\n",
      " | test_auc: 0.9364915807991958\n",
      "43/43 - 7s - loss: 0.3468 - auc: 0.9231 - val_loss: 0.3639 - val_auc: 0.9149\n",
      "Epoch 12/30\n",
      " | val_auc: 0.9175629058441559\n",
      " | test_auc: 0.9377481779341543\n",
      "43/43 - 7s - loss: 0.3284 - auc: 0.9321 - val_loss: 0.3622 - val_auc: 0.9176\n",
      "Epoch 13/30\n",
      " | val_auc: 0.9197950487012987\n",
      " | test_auc: 0.9383010806735361\n",
      "43/43 - 7s - loss: 0.3242 - auc: 0.9316 - val_loss: 0.3607 - val_auc: 0.9197\n",
      "Epoch 14/30\n",
      " | val_auc: 0.9189326298701298\n",
      " | test_auc: 0.939607941693893\n",
      "43/43 - 7s - loss: 0.3201 - auc: 0.9333 - val_loss: 0.3573 - val_auc: 0.9189\n",
      "Epoch 15/30\n",
      " | val_auc: 0.9198457792207791\n",
      " | test_auc: 0.9409148027142499\n",
      "43/43 - 7s - loss: 0.3148 - auc: 0.9365 - val_loss: 0.3572 - val_auc: 0.9191\n",
      "Epoch 16/30\n",
      " | val_auc: 0.9210125811688312\n",
      " | test_auc: 0.9423724553908017\n",
      "43/43 - 6s - loss: 0.3060 - auc: 0.9417 - val_loss: 0.3561 - val_auc: 0.9209\n",
      "Epoch 17/30\n",
      " | val_auc: 0.9217228084415584\n",
      " | test_auc: 0.9422719276200051\n",
      "43/43 - 7s - loss: 0.3016 - auc: 0.9424 - val_loss: 0.3532 - val_auc: 0.9214\n",
      "Epoch 18/30\n",
      " | val_auc: 0.9227881493506493\n",
      " | test_auc: 0.9442824830359386\n",
      "43/43 - 7s - loss: 0.2882 - auc: 0.9478 - val_loss: 0.3578 - val_auc: 0.9226\n",
      "Epoch 19/30\n",
      " | val_auc: 0.9216720779220778\n",
      " | test_auc: 0.9447348580045238\n",
      "43/43 - 7s - loss: 0.2928 - auc: 0.9430 - val_loss: 0.3504 - val_auc: 0.9220\n",
      "Epoch 20/30\n",
      " | val_auc: 0.9222808441558442\n",
      " | test_auc: 0.9459914551394824\n",
      "43/43 - 7s - loss: 0.2780 - auc: 0.9512 - val_loss: 0.3525 - val_auc: 0.9224\n",
      "Epoch 21/30\n",
      " | val_auc: 0.9217228084415584\n",
      " | test_auc: 0.9453882885147022\n",
      "43/43 - 7s - loss: 0.2714 - auc: 0.9533 - val_loss: 0.3511 - val_auc: 0.9220\n",
      "Epoch 22/30\n",
      " | val_auc: 0.9226866883116883\n",
      " | test_auc: 0.9452877607439055\n",
      "43/43 - 7s - loss: 0.2716 - auc: 0.9530 - val_loss: 0.3526 - val_auc: 0.9227\n",
      "Epoch 23/30\n",
      " | val_auc: 0.9226359577922078\n",
      " | test_auc: 0.9459914551394822\n",
      "43/43 - 6s - loss: 0.2579 - auc: 0.9589 - val_loss: 0.3508 - val_auc: 0.9221\n",
      "Epoch 24/30\n",
      " | val_auc: 0.9228388798701298\n",
      " | test_auc: 0.9451872329731088\n",
      "43/43 - 6s - loss: 0.2602 - auc: 0.9571 - val_loss: 0.3534 - val_auc: 0.9234\n",
      "Epoch 25/30\n",
      " | val_auc: 0.9245637175324675\n",
      " | test_auc: 0.9459411912540839\n",
      "43/43 - 7s - loss: 0.2538 - auc: 0.9603 - val_loss: 0.3518 - val_auc: 0.9247\n",
      "Epoch 26/30\n",
      " | val_auc: 0.9238027597402598\n",
      " | test_auc: 0.946544357878864\n",
      "43/43 - 6s - loss: 0.2473 - auc: 0.9626 - val_loss: 0.3554 - val_auc: 0.9239\n",
      "Epoch 27/30\n",
      " | val_auc: 0.9224330357142858\n",
      " | test_auc: 0.9453882885147022\n",
      "43/43 - 7s - loss: 0.2496 - auc: 0.9598 - val_loss: 0.3516 - val_auc: 0.9229\n",
      "Epoch 28/30\n",
      " | val_auc: 0.9233969155844156\n",
      " | test_auc: 0.9460417190248807\n",
      "43/43 - 7s - loss: 0.2389 - auc: 0.9639 - val_loss: 0.3515 - val_auc: 0.9240\n",
      "Epoch 29/30\n",
      " | val_auc: 0.9245637175324676\n",
      " | test_auc: 0.9475998994722292\n",
      "43/43 - 6s - loss: 0.2368 - auc: 0.9660 - val_loss: 0.3510 - val_auc: 0.9251\n",
      "Epoch 30/30\n",
      " | val_auc: 0.925679788961039\n",
      " | test_auc: 0.9475496355868309\n",
      "43/43 - 7s - loss: 0.2284 - auc: 0.9683 - val_loss: 0.3517 - val_auc: 0.9258\n",
      "\n",
      "Results: Loss = 0.28241729736328125 , AUC = 0.9480522871017456 \n",
      "\n",
      "val: 0.925679788961039\n",
      "test 0.9475496355868309\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Epoch 1/30\n",
      " | val_auc: 0.7711805555555556\n",
      " | test_auc: 0.7511091609380333\n",
      "43/43 - 7s - loss: 0.7447 - auc: 0.5585 - val_loss: 0.6561 - val_auc: 0.7708\n",
      "Epoch 2/30\n",
      " | val_auc: 0.8467757936507936\n",
      " | test_auc: 0.8110769830822486\n",
      "43/43 - 7s - loss: 0.5773 - auc: 0.7433 - val_loss: 0.5895 - val_auc: 0.8463\n",
      "Epoch 3/30\n",
      " | val_auc: 0.9010912698412699\n",
      " | test_auc: 0.8686558432060846\n",
      "43/43 - 6s - loss: 0.5385 - auc: 0.7915 - val_loss: 0.5358 - val_auc: 0.9015\n",
      "Epoch 4/30\n",
      " | val_auc: 0.9224702380952381\n",
      " | test_auc: 0.8960070206230804\n",
      "43/43 - 7s - loss: 0.4596 - auc: 0.8594 - val_loss: 0.4880 - val_auc: 0.9226\n",
      "Epoch 5/30\n",
      " | val_auc: 0.926984126984127\n",
      " | test_auc: 0.9019062941836088\n",
      "43/43 - 7s - loss: 0.4294 - auc: 0.8798 - val_loss: 0.4469 - val_auc: 0.9266\n",
      "Epoch 6/30\n",
      " | val_auc: 0.9283234126984127\n",
      " | test_auc: 0.9024913461069669\n",
      "43/43 - 6s - loss: 0.4125 - auc: 0.8882 - val_loss: 0.4103 - val_auc: 0.9282\n",
      "Epoch 7/30\n",
      " | val_auc: 0.9326388888888889\n",
      " | test_auc: 0.9059529033201696\n",
      "43/43 - 7s - loss: 0.3964 - auc: 0.8993 - val_loss: 0.3774 - val_auc: 0.9328\n",
      "Epoch 8/30\n",
      " | val_auc: 0.9328869047619047\n",
      " | test_auc: 0.9057091316854371\n",
      "43/43 - 6s - loss: 0.3529 - auc: 0.9244 - val_loss: 0.3604 - val_auc: 0.9330\n",
      "Epoch 9/30\n",
      " | val_auc: 0.9339781746031746\n",
      " | test_auc: 0.9065379552435278\n",
      "43/43 - 7s - loss: 0.3589 - auc: 0.9195 - val_loss: 0.3435 - val_auc: 0.9340\n",
      "Epoch 10/30\n",
      " | val_auc: 0.9334325396825397\n",
      " | test_auc: 0.9074155331285652\n",
      "43/43 - 7s - loss: 0.3439 - auc: 0.9251 - val_loss: 0.3368 - val_auc: 0.9335\n",
      "Epoch 11/30\n",
      " | val_auc: 0.936359126984127\n",
      " | test_auc: 0.9086831456291745\n",
      "43/43 - 7s - loss: 0.3212 - auc: 0.9379 - val_loss: 0.3254 - val_auc: 0.9365\n",
      "Epoch 12/30\n",
      " | val_auc: 0.9367063492063493\n",
      " | test_auc: 0.9102432840914632\n",
      "43/43 - 6s - loss: 0.3194 - auc: 0.9355 - val_loss: 0.3213 - val_auc: 0.9367\n",
      "Epoch 13/30\n",
      " | val_auc: 0.9353670634920634\n",
      " | test_auc: 0.9112183706303935\n",
      "43/43 - 6s - loss: 0.3072 - auc: 0.9444 - val_loss: 0.3216 - val_auc: 0.9355\n",
      "Epoch 14/30\n",
      " | val_auc: 0.9365079365079364\n",
      " | test_auc: 0.9127297547657355\n",
      "43/43 - 6s - loss: 0.2998 - auc: 0.9456 - val_loss: 0.3183 - val_auc: 0.9366\n",
      "Epoch 15/30\n",
      " | val_auc: 0.9368551587301588\n",
      " | test_auc: 0.9139486129393983\n",
      "43/43 - 7s - loss: 0.2983 - auc: 0.9449 - val_loss: 0.3138 - val_auc: 0.9368\n",
      "Epoch 16/30\n",
      " | val_auc: 0.9363095238095237\n",
      " | test_auc: 0.914387401881917\n",
      "43/43 - 7s - loss: 0.3000 - auc: 0.9432 - val_loss: 0.3128 - val_auc: 0.9362\n",
      "Epoch 17/30\n",
      " | val_auc: 0.937797619047619\n",
      " | test_auc: 0.9171176441909219\n",
      "43/43 - 7s - loss: 0.2730 - auc: 0.9547 - val_loss: 0.3115 - val_auc: 0.9377\n",
      "Epoch 18/30\n",
      " | val_auc: 0.9368551587301588\n",
      " | test_auc: 0.9169226268831359\n",
      "43/43 - 6s - loss: 0.2702 - auc: 0.9564 - val_loss: 0.3127 - val_auc: 0.9369\n",
      "Epoch 19/30\n",
      " | val_auc: 0.9371031746031746\n",
      " | test_auc: 0.9176051874603871\n",
      "43/43 - 6s - loss: 0.2804 - auc: 0.9485 - val_loss: 0.3115 - val_auc: 0.9373\n",
      "Epoch 20/30\n",
      " | val_auc: 0.9366071428571429\n",
      " | test_auc: 0.9174589244795475\n",
      "43/43 - 7s - loss: 0.2651 - auc: 0.9549 - val_loss: 0.3131 - val_auc: 0.9366\n",
      "Epoch 21/30\n",
      " | val_auc: 0.9387400793650793\n",
      " | test_auc: 0.9198478864999269\n",
      "43/43 - 7s - loss: 0.2537 - auc: 0.9609 - val_loss: 0.3069 - val_auc: 0.9386\n",
      "Epoch 22/30\n",
      " | val_auc: 0.9388888888888889\n",
      " | test_auc: 0.9200429038077129\n",
      "43/43 - 7s - loss: 0.2524 - auc: 0.9615 - val_loss: 0.3059 - val_auc: 0.9387\n",
      "Epoch 23/30\n",
      " | val_auc: 0.9384424603174603\n",
      " | test_auc: 0.9209204816927502\n",
      "43/43 - 7s - loss: 0.2396 - auc: 0.9655 - val_loss: 0.3107 - val_auc: 0.9384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      " | val_auc: 0.9375496031746032\n",
      " | test_auc: 0.920725464384964\n",
      "43/43 - 6s - loss: 0.2404 - auc: 0.9634 - val_loss: 0.3097 - val_auc: 0.9374\n",
      "Epoch 25/30\n",
      " | val_auc: 0.9373015873015874\n",
      " | test_auc: 0.9211642533274829\n",
      "43/43 - 6s - loss: 0.2322 - auc: 0.9665 - val_loss: 0.3136 - val_auc: 0.9373\n",
      "Epoch 26/30\n",
      " | val_auc: 0.9383432539682539\n",
      " | test_auc: 0.9223831115011458\n",
      "43/43 - 6s - loss: 0.2342 - auc: 0.9653 - val_loss: 0.3089 - val_auc: 0.9383\n",
      "Epoch 27/30\n",
      " | val_auc: 0.9393849206349206\n",
      " | test_auc: 0.9220418312125201\n",
      "43/43 - 7s - loss: 0.2266 - auc: 0.9691 - val_loss: 0.3044 - val_auc: 0.9398\n",
      "Epoch 28/30\n",
      " | val_auc: 0.9397321428571428\n",
      " | test_auc: 0.923260689386183\n",
      "43/43 - 7s - loss: 0.2271 - auc: 0.9696 - val_loss: 0.3077 - val_auc: 0.9398\n",
      "Epoch 29/30\n",
      " | val_auc: 0.9399305555555556\n",
      " | test_auc: 0.9233094437131296\n",
      "43/43 - 6s - loss: 0.2194 - auc: 0.9708 - val_loss: 0.3055 - val_auc: 0.9394\n",
      "Epoch 30/30\n",
      " | val_auc: 0.9375496031746032\n",
      " | test_auc: 0.92316318073229\n",
      "43/43 - 6s - loss: 0.2247 - auc: 0.9692 - val_loss: 0.3132 - val_auc: 0.9376\n",
      "\n",
      "Results: Loss = 0.3511112630367279 , AUC = 0.9232850670814514 \n",
      "\n",
      "val: 0.9375496031746032\n",
      "test 0.92316318073229\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Epoch 1/30\n",
      " | val_auc: 0.6398177838855805\n",
      " | test_auc: 0.5700911554570091\n",
      "43/43 - 7s - loss: 0.7386 - auc: 0.5724 - val_loss: 0.6685 - val_auc: 0.6403\n",
      "Epoch 2/30\n",
      " | val_auc: 0.7882882882882883\n",
      " | test_auc: 0.7549150036954915\n",
      "43/43 - 7s - loss: 0.5898 - auc: 0.7402 - val_loss: 0.6048 - val_auc: 0.7886\n",
      "Epoch 3/30\n",
      " | val_auc: 0.8432585127500382\n",
      " | test_auc: 0.827790096082779\n",
      "43/43 - 6s - loss: 0.5139 - auc: 0.8143 - val_loss: 0.5500 - val_auc: 0.8433\n",
      "Epoch 4/30\n",
      " | val_auc: 0.8754262737313584\n",
      " | test_auc: 0.8796255235279625\n",
      "43/43 - 7s - loss: 0.4571 - auc: 0.8602 - val_loss: 0.5066 - val_auc: 0.8747\n",
      "Epoch 5/30\n",
      " | val_auc: 0.8879981676591847\n",
      " | test_auc: 0.908450357230845\n",
      "43/43 - 7s - loss: 0.4421 - auc: 0.8689 - val_loss: 0.4641 - val_auc: 0.8875\n",
      "Epoch 6/30\n",
      " | val_auc: 0.8965999898203288\n",
      " | test_auc: 0.9249076127124907\n",
      "43/43 - 6s - loss: 0.4245 - auc: 0.8856 - val_loss: 0.4304 - val_auc: 0.8963\n",
      "Epoch 7/30\n",
      " | val_auc: 0.9014862319947066\n",
      " | test_auc: 0.9322985957132298\n",
      "43/43 - 7s - loss: 0.3880 - auc: 0.9033 - val_loss: 0.4038 - val_auc: 0.9010\n",
      "Epoch 8/30\n",
      " | val_auc: 0.9035730645900137\n",
      " | test_auc: 0.9385562946538556\n",
      "43/43 - 7s - loss: 0.3825 - auc: 0.9092 - val_loss: 0.3855 - val_auc: 0.9035\n",
      "Epoch 9/30\n",
      " | val_auc: 0.904234743217794\n",
      " | test_auc: 0.9419561468341956\n",
      "43/43 - 6s - loss: 0.3700 - auc: 0.9113 - val_loss: 0.3769 - val_auc: 0.9043\n",
      "Epoch 10/30\n",
      " | val_auc: 0.9065760675930168\n",
      " | test_auc: 0.9447154471544715\n",
      "43/43 - 6s - loss: 0.3496 - auc: 0.9232 - val_loss: 0.3697 - val_auc: 0.9065\n",
      "Epoch 11/30\n",
      " | val_auc: 0.9088155952562732\n",
      " | test_auc: 0.9462429169746243\n",
      "43/43 - 7s - loss: 0.3420 - auc: 0.9261 - val_loss: 0.3606 - val_auc: 0.9088\n",
      "Epoch 12/30\n",
      " | val_auc: 0.908713798544307\n",
      " | test_auc: 0.9480167528948017\n",
      "43/43 - 6s - loss: 0.3199 - auc: 0.9366 - val_loss: 0.3587 - val_auc: 0.9088\n",
      "Epoch 13/30\n",
      " | val_auc: 0.9083066116964422\n",
      " | test_auc: 0.94910076373491\n",
      "43/43 - 6s - loss: 0.3034 - auc: 0.9433 - val_loss: 0.3570 - val_auc: 0.9085\n",
      "Epoch 14/30\n",
      " | val_auc: 0.9123275818191072\n",
      " | test_auc: 0.9513180586351317\n",
      "43/43 - 7s - loss: 0.3155 - auc: 0.9381 - val_loss: 0.3473 - val_auc: 0.9122\n",
      "Epoch 15/30\n",
      " | val_auc: 0.9115641064793607\n",
      " | test_auc: 0.9523527962552353\n",
      "43/43 - 6s - loss: 0.2988 - auc: 0.9454 - val_loss: 0.3466 - val_auc: 0.9118\n",
      "Epoch 16/30\n",
      " | val_auc: 0.9130401588028707\n",
      " | test_auc: 0.9529933481152993\n",
      "43/43 - 7s - loss: 0.3032 - auc: 0.9416 - val_loss: 0.3428 - val_auc: 0.9125\n",
      "Epoch 17/30\n",
      " | val_auc: 0.9120730900391917\n",
      " | test_auc: 0.9542744518354274\n",
      "43/43 - 7s - loss: 0.2791 - auc: 0.9509 - val_loss: 0.3452 - val_auc: 0.9124\n",
      "Epoch 18/30\n",
      " | val_auc: 0.9152796864661272\n",
      " | test_auc: 0.9553584626755358\n",
      "43/43 - 7s - loss: 0.2765 - auc: 0.9530 - val_loss: 0.3386 - val_auc: 0.9150\n",
      "Epoch 19/30\n",
      " | val_auc: 0.9128874637349215\n",
      " | test_auc: 0.9552106430155209\n",
      "43/43 - 7s - loss: 0.2806 - auc: 0.9525 - val_loss: 0.3450 - val_auc: 0.9129\n",
      "Epoch 20/30\n",
      " | val_auc: 0.9146689061943298\n",
      " | test_auc: 0.9555555555555555\n",
      "43/43 - 6s - loss: 0.2719 - auc: 0.9548 - val_loss: 0.3418 - val_auc: 0.9147\n",
      "Epoch 21/30\n",
      " | val_auc: 0.9156359749580089\n",
      " | test_auc: 0.9567873860556787\n",
      "43/43 - 7s - loss: 0.2691 - auc: 0.9554 - val_loss: 0.3409 - val_auc: 0.9158\n",
      "Epoch 22/30\n",
      " | val_auc: 0.9145162111263805\n",
      " | test_auc: 0.9560482877556047\n",
      "43/43 - 7s - loss: 0.2764 - auc: 0.9518 - val_loss: 0.3439 - val_auc: 0.9138\n",
      "Epoch 23/30\n",
      " | val_auc: 0.9162976535857892\n",
      " | test_auc: 0.9575264843557526\n",
      "43/43 - 7s - loss: 0.2585 - auc: 0.9574 - val_loss: 0.3460 - val_auc: 0.9170\n",
      "Epoch 24/30\n",
      " | val_auc: 0.9166030437216878\n",
      " | test_auc: 0.9571815718157182\n",
      "43/43 - 7s - loss: 0.2585 - auc: 0.9584 - val_loss: 0.3395 - val_auc: 0.9166\n",
      "Epoch 25/30\n",
      " | val_auc: 0.9175701124853668\n",
      " | test_auc: 0.9579206701157921\n",
      "43/43 - 7s - loss: 0.2474 - auc: 0.9632 - val_loss: 0.3342 - val_auc: 0.9179\n",
      "Epoch 26/30\n",
      " | val_auc: 0.9174174174174174\n",
      " | test_auc: 0.9577235772357723\n",
      "43/43 - 7s - loss: 0.2434 - auc: 0.9636 - val_loss: 0.3374 - val_auc: 0.9174\n",
      "Epoch 27/30\n",
      " | val_auc: 0.9187407746729782\n",
      " | test_auc: 0.9584134023158413\n",
      "43/43 - 6s - loss: 0.2466 - auc: 0.9610 - val_loss: 0.3351 - val_auc: 0.9188\n",
      "Epoch 28/30\n",
      " | val_auc: 0.9200641319285388\n",
      " | test_auc: 0.9590539541759053\n",
      "43/43 - 6s - loss: 0.2382 - auc: 0.9655 - val_loss: 0.3324 - val_auc: 0.9199\n",
      "Epoch 29/30\n",
      " | val_auc: 0.9188425713849443\n",
      " | test_auc: 0.958659768415866\n",
      "43/43 - 6s - loss: 0.2366 - auc: 0.9654 - val_loss: 0.3404 - val_auc: 0.9187\n",
      "Epoch 30/30\n",
      " | val_auc: 0.9174174174174174\n",
      " | test_auc: 0.9598915989159892\n",
      "43/43 - 6s - loss: 0.2229 - auc: 0.9708 - val_loss: 0.3408 - val_auc: 0.9174\n",
      "\n",
      "Results: Loss = 0.24715359508991241 , AUC = 0.9598177075386047 \n",
      "\n",
      "val: 0.9174174174174174\n",
      "test 0.9598915989159892\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Epoch 1/30\n",
      " | val_auc: 0.5664942103966495\n",
      " | test_auc: 0.6063987727025288\n",
      "43/43 - 7s - loss: 0.7238 - auc: 0.6089 - val_loss: 0.6822 - val_auc: 0.5659\n",
      "Epoch 2/30\n",
      " | val_auc: 0.7570337521557033\n",
      " | test_auc: 0.7870787350917999\n",
      "43/43 - 6s - loss: 0.5688 - auc: 0.7617 - val_loss: 0.6278 - val_auc: 0.7568\n",
      "Epoch 3/30\n",
      " | val_auc: 0.8486326681448633\n",
      " | test_auc: 0.8480477062404118\n",
      "43/43 - 6s - loss: 0.5131 - auc: 0.8093 - val_loss: 0.5801 - val_auc: 0.8490\n",
      "Epoch 4/30\n",
      " | val_auc: 0.8737620103473761\n",
      " | test_auc: 0.8740782897015885\n",
      "43/43 - 6s - loss: 0.4764 - auc: 0.8441 - val_loss: 0.5379 - val_auc: 0.8741\n",
      "Epoch 5/30\n",
      " | val_auc: 0.8906627248090663\n",
      " | test_auc: 0.892339288365418\n",
      "43/43 - 6s - loss: 0.4559 - auc: 0.8627 - val_loss: 0.4969 - val_auc: 0.8906\n",
      "Epoch 6/30\n",
      " | val_auc: 0.9000246366100024\n",
      " | test_auc: 0.9044637996733804\n",
      "43/43 - 6s - loss: 0.4320 - auc: 0.8797 - val_loss: 0.4604 - val_auc: 0.8998\n",
      "Epoch 7/30\n",
      " | val_auc: 0.9045577728504558\n",
      " | test_auc: 0.9118869698619291\n",
      "43/43 - 6s - loss: 0.4134 - auc: 0.8854 - val_loss: 0.4314 - val_auc: 0.9047\n",
      "Epoch 8/30\n",
      " | val_auc: 0.907119980290712\n",
      " | test_auc: 0.9139654575147227\n",
      "43/43 - 6s - loss: 0.3817 - auc: 0.9072 - val_loss: 0.4115 - val_auc: 0.9067\n",
      "Epoch 9/30\n",
      " | val_auc: 0.9093865484109386\n",
      " | test_auc: 0.9182708962240806\n",
      "43/43 - 6s - loss: 0.3666 - auc: 0.9139 - val_loss: 0.3964 - val_auc: 0.9093\n",
      "Epoch 10/30\n",
      " | val_auc: 0.9106676521310667\n",
      " | test_auc: 0.9204483594793883\n",
      "43/43 - 6s - loss: 0.3664 - auc: 0.9128 - val_loss: 0.3875 - val_auc: 0.9108\n",
      "Epoch 11/30\n",
      " | val_auc: 0.9124414880512441\n",
      " | test_auc: 0.922031969119612\n",
      "43/43 - 6s - loss: 0.3462 - auc: 0.9228 - val_loss: 0.3828 - val_auc: 0.9124\n",
      "Epoch 12/30\n",
      " | val_auc: 0.9132298595713229\n",
      " | test_auc: 0.9241104567724057\n",
      "43/43 - 6s - loss: 0.3460 - auc: 0.9198 - val_loss: 0.3755 - val_auc: 0.9133\n",
      "Epoch 13/30\n",
      " | val_auc: 0.9149544222714954\n",
      " | test_auc: 0.927574602860395\n",
      "43/43 - 6s - loss: 0.3215 - auc: 0.9338 - val_loss: 0.3702 - val_auc: 0.9145\n",
      "Epoch 14/30\n",
      " | val_auc: 0.9147573293914757\n",
      " | test_auc: 0.9282179442767359\n",
      "43/43 - 6s - loss: 0.3263 - auc: 0.9320 - val_loss: 0.3681 - val_auc: 0.9145\n",
      "Epoch 15/30\n",
      " | val_auc: 0.9150529687115053\n",
      " | test_auc: 0.9297025783144454\n",
      "43/43 - 6s - loss: 0.3196 - auc: 0.9325 - val_loss: 0.3663 - val_auc: 0.9151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      " | val_auc: 0.915989159891599\n",
      " | test_auc: 0.931682090364725\n",
      "43/43 - 6s - loss: 0.2961 - auc: 0.9444 - val_loss: 0.3637 - val_auc: 0.9157\n",
      "Epoch 17/30\n",
      " | val_auc: 0.9163340724316333\n",
      " | test_auc: 0.9329687731974068\n",
      "43/43 - 6s - loss: 0.2945 - auc: 0.9443 - val_loss: 0.3625 - val_auc: 0.9160\n",
      "Epoch 18/30\n",
      " | val_auc: 0.9169253510716924\n",
      " | test_auc: 0.9337110902162618\n",
      "43/43 - 6s - loss: 0.2818 - auc: 0.9501 - val_loss: 0.3585 - val_auc: 0.9168\n",
      "Epoch 19/30\n",
      " | val_auc: 0.9170731707317072\n",
      " | test_auc: 0.9344039194338596\n",
      "43/43 - 6s - loss: 0.2888 - auc: 0.9457 - val_loss: 0.3588 - val_auc: 0.9167\n",
      "Epoch 20/30\n",
      " | val_auc: 0.9163833456516384\n",
      " | test_auc: 0.9342059682288317\n",
      "43/43 - 6s - loss: 0.2718 - auc: 0.9536 - val_loss: 0.3579 - val_auc: 0.9167\n",
      "Epoch 21/30\n",
      " | val_auc: 0.9171717171717171\n",
      " | test_auc: 0.9360865046765972\n",
      "43/43 - 6s - loss: 0.2760 - auc: 0.9510 - val_loss: 0.3563 - val_auc: 0.9170\n",
      "Epoch 22/30\n",
      " | val_auc: 0.9168760778516876\n",
      " | test_auc: 0.9363834314841392\n",
      "43/43 - 6s - loss: 0.2678 - auc: 0.9541 - val_loss: 0.3565 - val_auc: 0.9166\n",
      "Epoch 23/30\n",
      " | val_auc: 0.9174180832717418\n",
      " | test_auc: 0.9368288216954521\n",
      "43/43 - 6s - loss: 0.2581 - auc: 0.9581 - val_loss: 0.3555 - val_auc: 0.9171\n",
      "Epoch 24/30\n",
      " | val_auc: 0.9182064547918207\n",
      " | test_auc: 0.9370267729004801\n",
      "43/43 - 6s - loss: 0.2559 - auc: 0.9573 - val_loss: 0.3556 - val_auc: 0.9178\n",
      "Epoch 25/30\n",
      " | val_auc: 0.9187977334318798\n",
      " | test_auc: 0.9367298460929381\n",
      "43/43 - 6s - loss: 0.2502 - auc: 0.9606 - val_loss: 0.3546 - val_auc: 0.9179\n",
      "Epoch 26/30\n",
      " | val_auc: 0.9185020941118502\n",
      " | test_auc: 0.937323699708022\n",
      "43/43 - 6s - loss: 0.2533 - auc: 0.9604 - val_loss: 0.3544 - val_auc: 0.9178\n",
      "Epoch 27/30\n",
      " | val_auc: 0.9184035476718404\n",
      " | test_auc: 0.9371257485029941\n",
      "43/43 - 6s - loss: 0.2459 - auc: 0.9621 - val_loss: 0.3543 - val_auc: 0.9176\n",
      "Epoch 28/30\n",
      " | val_auc: 0.9182557280118255\n",
      " | test_auc: 0.9371752363042511\n",
      "43/43 - 6s - loss: 0.2428 - auc: 0.9630 - val_loss: 0.3554 - val_auc: 0.9180\n",
      "Epoch 29/30\n",
      " | val_auc: 0.9185020941118501\n",
      " | test_auc: 0.9380660167268768\n",
      "43/43 - 6s - loss: 0.2348 - auc: 0.9657 - val_loss: 0.3543 - val_auc: 0.9182\n",
      "Epoch 30/30\n",
      " | val_auc: 0.9183050012318305\n",
      " | test_auc: 0.9376701143168209\n",
      "43/43 - 6s - loss: 0.2406 - auc: 0.9622 - val_loss: 0.3550 - val_auc: 0.9179\n",
      "\n",
      "Results: Loss = 0.30928361415863037 , AUC = 0.9372494220733643 \n",
      "\n",
      "val: 0.9183050012318305\n",
      "test 0.9376701143168209\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Epoch 1/30\n",
      " | val_auc: 0.6890297202797202\n",
      " | test_auc: 0.7472451437650556\n",
      "43/43 - 7s - loss: 0.6763 - auc: 0.6554 - val_loss: 0.6519 - val_auc: 0.6889\n",
      "Epoch 2/30\n",
      " | val_auc: 0.8163121600621601\n",
      " | test_auc: 0.8372456562964482\n",
      "43/43 - 6s - loss: 0.5574 - auc: 0.7739 - val_loss: 0.6034 - val_auc: 0.8158\n",
      "Epoch 3/30\n",
      " | val_auc: 0.868371212121212\n",
      " | test_auc: 0.8813746091948131\n",
      "43/43 - 6s - loss: 0.5017 - auc: 0.8211 - val_loss: 0.5571 - val_auc: 0.8685\n",
      "Epoch 4/30\n",
      " | val_auc: 0.8941093628593629\n",
      " | test_auc: 0.910486392291528\n",
      "43/43 - 6s - loss: 0.4625 - auc: 0.8572 - val_loss: 0.5070 - val_auc: 0.8940\n",
      "Epoch 5/30\n",
      " | val_auc: 0.910232128982129\n",
      " | test_auc: 0.9240172210547896\n",
      "43/43 - 6s - loss: 0.4179 - auc: 0.8853 - val_loss: 0.4589 - val_auc: 0.9103\n",
      "Epoch 6/30\n",
      " | val_auc: 0.9206245143745144\n",
      " | test_auc: 0.9331915329813951\n",
      "43/43 - 6s - loss: 0.4069 - auc: 0.8921 - val_loss: 0.4187 - val_auc: 0.9209\n",
      "Epoch 7/30\n",
      " | val_auc: 0.9266462703962705\n",
      " | test_auc: 0.9393931628312233\n",
      "43/43 - 6s - loss: 0.3967 - auc: 0.8965 - val_loss: 0.3849 - val_auc: 0.9268\n",
      "Epoch 8/30\n",
      " | val_auc: 0.9302884615384616\n",
      " | test_auc: 0.9411870227051407\n",
      "43/43 - 6s - loss: 0.3689 - auc: 0.9119 - val_loss: 0.3632 - val_auc: 0.9301\n",
      "Epoch 9/30\n",
      " | val_auc: 0.9324252136752136\n",
      " | test_auc: 0.943903439085644\n",
      "43/43 - 6s - loss: 0.3698 - auc: 0.9090 - val_loss: 0.3472 - val_auc: 0.9325\n",
      "Epoch 10/30\n",
      " | val_auc: 0.9349504662004662\n",
      " | test_auc: 0.9462610834913638\n",
      "43/43 - 6s - loss: 0.3556 - auc: 0.9152 - val_loss: 0.3369 - val_auc: 0.9347\n",
      "Epoch 11/30\n",
      " | val_auc: 0.9358245920745921\n",
      " | test_auc: 0.947388652554969\n",
      "43/43 - 6s - loss: 0.3602 - auc: 0.9149 - val_loss: 0.3296 - val_auc: 0.9357\n",
      "Epoch 12/30\n",
      " | val_auc: 0.9360674048174049\n",
      " | test_auc: 0.9481574496437907\n",
      "43/43 - 6s - loss: 0.3465 - auc: 0.9229 - val_loss: 0.3247 - val_auc: 0.9364\n",
      "Epoch 13/30\n",
      " | val_auc: 0.9373785936285937\n",
      " | test_auc: 0.950412587771001\n",
      "43/43 - 6s - loss: 0.3276 - auc: 0.9307 - val_loss: 0.3194 - val_auc: 0.9375\n",
      "Epoch 14/30\n",
      " | val_auc: 0.9384469696969697\n",
      " | test_auc: 0.9503100814924914\n",
      "43/43 - 6s - loss: 0.3220 - auc: 0.9321 - val_loss: 0.3162 - val_auc: 0.9385\n",
      "Epoch 15/30\n",
      " | val_auc: 0.9397581585081586\n",
      " | test_auc: 0.9518476756701347\n",
      "43/43 - 6s - loss: 0.3188 - auc: 0.9340 - val_loss: 0.3128 - val_auc: 0.9402\n",
      "Epoch 16/30\n",
      " | val_auc: 0.9408265345765346\n",
      " | test_auc: 0.9538978012403259\n",
      "43/43 - 6s - loss: 0.3076 - auc: 0.9399 - val_loss: 0.3089 - val_auc: 0.9407\n",
      "Epoch 17/30\n",
      " | val_auc: 0.9435460372960373\n",
      " | test_auc: 0.954820357746912\n",
      "43/43 - 6s - loss: 0.3070 - auc: 0.9397 - val_loss: 0.3053 - val_auc: 0.9434\n",
      "Epoch 18/30\n",
      " | val_auc: 0.9410693473193473\n",
      " | test_auc: 0.9534877761262877\n",
      "43/43 - 6s - loss: 0.2911 - auc: 0.9460 - val_loss: 0.3045 - val_auc: 0.9414\n",
      "Epoch 19/30\n",
      " | val_auc: 0.9427690365190365\n",
      " | test_auc: 0.9561529393675362\n",
      "43/43 - 6s - loss: 0.2931 - auc: 0.9441 - val_loss: 0.3017 - val_auc: 0.9430\n",
      "Epoch 20/30\n",
      " | val_auc: 0.9455371017871017\n",
      " | test_auc: 0.9570242427348675\n",
      "43/43 - 6s - loss: 0.2890 - auc: 0.9462 - val_loss: 0.2994 - val_auc: 0.9454\n",
      "Epoch 21/30\n",
      " | val_auc: 0.944128787878788\n",
      " | test_auc: 0.9562554456460459\n",
      "43/43 - 6s - loss: 0.2799 - auc: 0.9512 - val_loss: 0.2978 - val_auc: 0.9440\n",
      "Epoch 22/30\n",
      " | val_auc: 0.9450514763014761\n",
      " | test_auc: 0.9572805084311414\n",
      "43/43 - 6s - loss: 0.2798 - auc: 0.9498 - val_loss: 0.2958 - val_auc: 0.9447\n",
      "Epoch 23/30\n",
      " | val_auc: 0.9471882284382284\n",
      " | test_auc: 0.9579980523807085\n",
      "43/43 - 6s - loss: 0.2715 - auc: 0.9540 - val_loss: 0.2922 - val_auc: 0.9471\n",
      "Epoch 24/30\n",
      " | val_auc: 0.9457313519813519\n",
      " | test_auc: 0.9572292552918866\n",
      "43/43 - 6s - loss: 0.2632 - auc: 0.9564 - val_loss: 0.2922 - val_auc: 0.9457\n",
      "Epoch 25/30\n",
      " | val_auc: 0.9476252913752914\n",
      " | test_auc: 0.9577417866844343\n",
      "43/43 - 6s - loss: 0.2688 - auc: 0.9544 - val_loss: 0.2907 - val_auc: 0.9474\n",
      "Epoch 26/30\n",
      " | val_auc: 0.9471396658896658\n",
      " | test_auc: 0.9579980523807082\n",
      "43/43 - 6s - loss: 0.2579 - auc: 0.9574 - val_loss: 0.2897 - val_auc: 0.9474\n",
      "Epoch 27/30\n",
      " | val_auc: 0.9477224164724165\n",
      " | test_auc: 0.9583568243554917\n",
      "43/43 - 6s - loss: 0.2585 - auc: 0.9578 - val_loss: 0.2892 - val_auc: 0.9476\n",
      "Epoch 28/30\n",
      " | val_auc: 0.9474796037296037\n",
      " | test_auc: 0.9589718620265492\n",
      "43/43 - 6s - loss: 0.2390 - auc: 0.9653 - val_loss: 0.2894 - val_auc: 0.9476\n",
      "Epoch 29/30\n",
      " | val_auc: 0.9485479797979797\n",
      " | test_auc: 0.9602019373686638\n",
      "43/43 - 6s - loss: 0.2468 - auc: 0.9630 - val_loss: 0.2886 - val_auc: 0.9488\n",
      "Epoch 30/30\n",
      " | val_auc: 0.9480623543123543\n",
      " | test_auc: 0.9602531905079186\n",
      "43/43 - 6s - loss: 0.2424 - auc: 0.9645 - val_loss: 0.2896 - val_auc: 0.9483\n",
      "\n",
      "Results: Loss = 0.2511414885520935 , AUC = 0.9602275490760803 \n",
      "\n",
      "val: 0.9480623543123543\n",
      "test 0.9602531905079186\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create directory to save models\n",
    "rt_sv_dir = './supervised_learn/supervised_2000_2D_grayscale'\n",
    "!rm -r {rt_sv_dir}\n",
    "os.mkdir(rt_sv_dir)\n",
    "NUM_shuf= 5\n",
    "\n",
    "historys = {}\n",
    "# Run each split\n",
    "for RUN in range(NUM_shuf):\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        MERGM = build_model_1D()\n",
    "\n",
    "        Adam = tf.keras.optimizers.Adam(0.00001)\n",
    "\n",
    "        MERGM.compile(\n",
    "          optimizer = Adam,\n",
    "          loss = 'BinaryCrossentropy',\n",
    "          metrics=['AUC'])\n",
    "        \n",
    "        sup_data_size = len(sup_DATA[RUN]['MEL'])\n",
    "\n",
    "        timgs     = sup_DATA[RUN]['MEL'][:int(0.7*sup_data_size)]\n",
    "        labels    = sup_DATA[RUN]['LABELS'][:int(0.7*sup_data_size)]\n",
    "\n",
    "\n",
    "        test_imgs    = sup_DATA[RUN]['MEL'][ int(0.7*sup_data_size): int(0.85*sup_data_size)]\n",
    "        test_labels  = sup_DATA[RUN]['LABELS'][ int(0.7*sup_data_size): int(0.85*sup_data_size)]\n",
    "\n",
    "\n",
    "        val_imgs    = sup_DATA[RUN]['MEL'][ int(0.85*sup_data_size) :]\n",
    "        val_labels  = sup_DATA[RUN]['LABELS'][ int(0.85*sup_data_size) :]\n",
    "\n",
    "        imgs_em      = specGenerator_1D(timgs,labels,batch_size=32,target_size=(64,64))\n",
    "        TEST          = specGenerator_1D(test_imgs,test_labels,batch_size=32,target_size=(64,64))\n",
    "        VAL         = specGenerator_1D(val_imgs,val_labels,batch_size=32,target_size=(64,64))\n",
    "\n",
    "\n",
    "        evaluator = Evaluation(VAL, val_labels, TEST, test_labels)\n",
    "        checkpointer = keras.callbacks.ModelCheckpoint(filepath=os.path.join(os.path.join(rt_sv_dir, str(RUN)),\n",
    "                    \"{epoch:03d}--{val_loss:.3f}--{loss:.3f}.hdf5\"), save_best_only=False)\n",
    "        os.mkdir(os.path.join(rt_sv_dir, str(RUN)))\n",
    "        history = MERGM.fit_generator(\n",
    "                      imgs_em,\n",
    "                      epochs=30,\n",
    "                      validation_data=VAL, \n",
    "                      verbose=2, \n",
    "                      callbacks=[evaluator, checkpointer])\n",
    "        historys[RUN]=history.history\n",
    "\n",
    "        MERGM_Record1 = MERGM.evaluate_generator(\n",
    "        TEST\n",
    "        )\n",
    "        print()\n",
    "        print('Results: Loss = {} , AUC = {} '.format(MERGM_Record1[0],MERGM_Record1[1]))\n",
    "\n",
    "        print()\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        y_val  = val_labels\n",
    "        y_preds_val = MERGM.predict_generator(VAL)\n",
    "        print('val:', roc_auc_score(y_val[:len(y_preds_val)], y_preds_val))\n",
    "\n",
    "        y_test  = test_labels\n",
    "        y_preds_test = MERGM.predict(TEST)\n",
    "        print('test', roc_auc_score(y_test[:len(y_preds_test)], y_preds_test))\n",
    "        print()\n",
    "        print('-----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " | val_auc: 0.865919237012987\n",
      " | test_auc: 0.869942196531792\n",
      "43/43 - 6s - loss: 0.4815 - auc: 0.8695 - val_loss: 0.5978 - val_auc: 0.8663\n",
      "Epoch 2/20\n",
      " | val_auc: 0.9028003246753246\n",
      " | test_auc: 0.9086453882885147\n",
      "43/43 - 6s - loss: 0.3454 - auc: 0.9257 - val_loss: 0.6385 - val_auc: 0.9012\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e6f02e0abd4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                       callbacks=[evaluator, checkpointer])\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mhistorys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRUN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create directory to save models\n",
    "rt_sv_dir = './supervised_learn/supervised_1000_2D_grayscale'\n",
    "!rm -r {rt_sv_dir}\n",
    "os.mkdir(rt_sv_dir)\n",
    "         \n",
    "         \n",
    "NUM_shuf= 5\n",
    "\n",
    "historys = {}\n",
    "# Run each split\n",
    "for RUN in range(NUM_shuf):\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        MERGM = build_model_1D()\n",
    "\n",
    "        Adam = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "        MERGM.compile(\n",
    "          optimizer = Adam,\n",
    "          loss = 'BinaryCrossentropy',\n",
    "          metrics=['AUC'])\n",
    "        \n",
    "        sup_data_size = len(sup_DATA[RUN]['MEL'])\n",
    "\n",
    "        timgs     = sup_DATA[RUN]['MEL'][:int(0.7*sup_data_size)]\n",
    "        labels    = sup_DATA[RUN]['LABELS'][:int(0.7*sup_data_size)]\n",
    "\n",
    "\n",
    "        test_imgs    = sup_DATA[RUN]['MEL'][ int(0.7*sup_data_size): int(0.85*sup_data_size)]\n",
    "        test_labels  = sup_DATA[RUN]['LABELS'][ int(0.7*sup_data_size): int(0.85*sup_data_size)]\n",
    "      \n",
    "\n",
    "        val_imgs    = sup_DATA[RUN]['MEL'][ int(0.85*sup_data_size) :]\n",
    "        val_labels  = sup_DATA[RUN]['LABELS'][ int(0.85*sup_data_size) :]\n",
    "\n",
    "        imgs_em      = specGenerator_1D(timgs,labels,batch_size=32,target_size=(64,64))\n",
    "        TEST          = specGenerator_1D(test_imgs,test_labels,batch_size=32,target_size=(64,64))\n",
    "        VAL         = specGenerator_1D(val_imgs,val_labels,batch_size=32,target_size=(64,64))\n",
    "\n",
    "\n",
    "        evaluator = Evaluation(VAL, val_labels, TEST, test_labels)\n",
    "        checkpointer = keras.callbacks.ModelCheckpoint(filepath=os.path.join(os.path.join(rt_sv_dir, str(RUN)),\n",
    "                    \"{epoch:03d}--{val_loss:.3f}--{loss:.3f}.hdf5\"), save_best_only=False)\n",
    "        os.mkdir(os.path.join(rt_sv_dir, str(RUN)))\n",
    "        tf.random.set_seed(5)\n",
    "        history = MERGM.fit_generator(\n",
    "                      imgs_em,\n",
    "                      epochs=30,\n",
    "                      validation_data=VAL, \n",
    "                      verbose=2, \n",
    "                      callbacks=[evaluator, checkpointer])\n",
    "        historys[RUN]=history.history\n",
    "\n",
    "        MERGM_Record1 = MERGM.evaluate_generator(\n",
    "        TEST\n",
    "        )\n",
    "        print()\n",
    "        print('Results: Loss = {} , AUC = {} '.format(MERGM_Record1[0],MERGM_Record1[1]))\n",
    "\n",
    "        print()\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        y_val  = val_labels\n",
    "        y_preds_val = MERGM.predict_generator(VAL)\n",
    "        print('val:', roc_auc_score(y_val[:len(y_preds_val)], y_preds_val))\n",
    "\n",
    "        y_test  = test_labels\n",
    "        y_preds_test = MERGM.predict(TEST)\n",
    "        print('test', roc_auc_score(y_test[:len(y_preds_test)], y_preds_test))\n",
    "        print()\n",
    "        print('-----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAykElEQVR4nO3dd3gc1b3/8fdXq1WXbBVXWbbk3gAbF0w3EIiB0AMGAoEQICFwgYRwQ3Jvbgi/FJJwCYEbakICCcEhgCmhN1ONsTHGvVfJtizLtnrf8/tjxrYwqrZWZffzep59dnfm7O53vLAfzTkzZ8w5h4iIRLeYri5ARES6nsJAREQUBiIiojAQEREUBiIigsJARERQGIi0mZn91cx+0ca2G83sK4f6PiKdRWEgIiIKAxERURhIhPG7Z241s8VmVmFmfzazfmb2ipmVmdmbZpbeqP3ZZrbMzPaY2RwzG9No3UQzW+i/7p9AwgGf9TUzW+S/9iMzO/wga77GzNaa2S4ze8HMBvrLzcx+b2Y7zKzUzJaY2Xh/3RlmttyvrcDMfnhQ/2AiPoWBRKILgFOBkcBZwCvAT4A+eP/N3whgZiOBJ4Gb/XUvAy+aWZyZxQHPAX8DMoB/+e+L/9qJwKPAd4BM4CHgBTOLb0+hZnYy8GvgImAAsAmY5a8+DTjB345efptif92fge8451KB8cDb7flckQMpDCQS3eecK3TOFQDvA/Occ58556qB2cBEv91M4CXn3BvOuTrgLiAROAaYBgSBe5xzdc65p4H5jT7jWuAh59w851yDc+4xoMZ/XXt8A3jUObfQOVcD/Bg42sxygTogFRgNmHNuhXNum/+6OmCsmaU553Y75xa283NFvkBhIJGosNHjqiaep/iPB+L9JQ6Acy4EbAGy/XUF7oszOW5q9HgIcIvfRbTHzPYAOf7r2uPAGsrx/vrPds69Dfwf8Edgh5k9bGZpftMLgDOATWb2rpkd3c7PFfkChYFEs614P+qA10eP94NeAGwDsv1lew1u9HgL8EvnXO9GtyTn3JOHWEMyXrdTAYBz7l7n3CRgLF530a3+8vnOuXOAvnjdWU+183NFvkBhINHsKeBMMzvFzILALXhdPR8Bc4F64EYzC5rZ+cDURq99BPiumR3lD/Qmm9mZZpbazhqeBL5lZhP88YZf4XVrbTSzKf77B4EKoBoI+WMa3zCzXn73VikQOoR/BxGFgUQv59wq4DLgPmAn3mDzWc65WudcLXA+cCWwC2984dlGr10AXIPXjbMbWOu3bW8NbwI/BZ7B2xsZBlzsr07DC53deF1JxcDv/HWXAxvNrBT4Lt7Yg8hBM13cRkREtGcgIiIKAxERURiIiAgKAxERAWK7uoD2ysrKcrm5uV1dhohIj/Lpp5/udM71aW59jwuD3NxcFixY0NVliIj0KGa2qaX16iYSERGFgYiIKAxERIQeOGbQlLq6OvLz86muru7qUsIqISGBQYMGEQwGu7oUEYkwEREG+fn5pKamkpubyxcnmYwczjmKi4vJz88nLy+vq8sRkQgTEd1E1dXVZGZmRmwQAJgZmZmZEb/3IyJdIyLCAIjoINgrGrZRRLpGxIRBaypq6tlWUoVmaRUR+bKoCYOqugaKymqob+j4MNizZw/3339/u193xhlnsGfPng6vR0SkvaImDBKDAcALhY7WXBjU19e3+LqXX36Z3r17d3g9IiLtFRFHE7VFQqMwSEvs2EMzb7vtNtatW8eECRMIBoMkJCSQnp7OypUrWb16Neeeey5btmyhurqam266iWuvvRbYP7VGeXk5p59+OscddxwfffQR2dnZPP/88yQmJnZonSIizYm4MPj5i8tYvrW0yXVVtQ2Y7Q+Gtho7MI2fnTWu2fV33nknS5cuZdGiRcyZM4czzzyTpUuX7jsE9NFHHyUjI4OqqiqmTJnCBRdcQGZm5hfeY82aNTz55JM88sgjXHTRRTzzzDNcdtll7apTRORgRVwYtCQmxmgIhX8AeerUqV84F+Dee+9l9uzZAGzZsoU1a9Z8KQzy8vKYMGECAJMmTWLjxo1hr1NEZK+IC4OW/oIvKqthW0kVYwakEQyEb7gkOTl53+M5c+bw5ptvMnfuXJKSkpg+fXqT5wrEx8fvexwIBKiqqgpbfSIiB4qaAWTYP4hc3cGDyKmpqZSVlTW5rqSkhPT0dJKSkli5ciUff/xxh362iEhHiLg9g5YkxHnZV1XbQGpCxw0iZ2ZmcuyxxzJ+/HgSExPp16/fvnUzZszgwQcfZMyYMYwaNYpp06Z12OeKiHQU62knYU2ePNkdeHGbFStWMGbMmDa9fuX2UhKDAYZkJrfeuBtqz7aKiOxlZp865yY3tz6quonA6yoKx7kGIiI9WfSEQV0VlG4jMS5AbX2I+oZQV1ckItJtRE8Y1JRB+XZSqAE6fhBZRKQni54wSMqEmFgSaooAqKrTnoGIyF7REwYxAUjuQ0xtGamBOo0biIg0Ej1hAJCcBRagr+2hqlZhICKyV3SFQUwsJGeRFCqH+upOmZqiKSkpKV3yuSIizYmuMABI7gvE0Nf2aBBZRMQXVWcgAxCIJZSUSe+KInbXVJEcn3rIb3nbbbeRk5PD9ddfD8Dtt99ObGws77zzDrt376auro5f/OIXnHPOOYf8WSIi4RB5YfDKbbB9SYtNYlwI6irpZQEItuGaAf0Pg9PvbHb1zJkzufnmm/eFwVNPPcVrr73GjTfeSFpaGjt37mTatGmcffbZuo6xiHRLkRcGbWAWQz0BAq4BCHGovWUTJ05kx44dbN26laKiItLT0+nfvz/f//73ee+994iJiaGgoIDCwkL69+/fIdsgItKRIi8MWvgLvrHde0rJqliHS+mD9Rp0yB974YUX8vTTT7N9+3ZmzpzJE088QVFREZ9++inBYJDc3Nwmp64WEekOom8A2RcXn8AeUqCiGBpavlZxW8ycOZNZs2bx9NNPc+GFF1JSUkLfvn0JBoO88847bNq0qQOqFhEJj6gNg8RggCLXGyMEFUWH/H7jxo2jrKyM7OxsBgwYwDe+8Q0WLFjAYYcdxuOPP87o0aM7oGoRkfCIvG6iNgoGYqiLiaMqJoXEiiJI6eudpXwIlizZP3CdlZXF3Llzm2xXXl5+SJ8jItLRonbPwMxIDAbYaengGqBiZ1eXJCLSZaI2DAAS4wLsqQ/i4lKhYgeENHmdiESniAmDg7liW2IwgHOO2sQ+EKqHyuIwVNZxetpV6USk54iIMEhISKC4uLjdP5aJQW+MoIJEiEuG8kJw3XPvwDlHcXExCQkJXV2KiESgiBhAHjRoEPn5+RQVte+oIOegqKSKisIAvYMN3lFFhVUQ1z0nkktISGDQoEM/J0JE5EAREQbBYJC8vLyDeu3tD86lPhTi2euOgYdPhJpyuGH+IR9ZJCLSk0REN9GhGJedxvJtpTQ44PhbYNc6WP5cV5clItKpoj4Mxg/sRXVdiPVF5TD6LMgaCe/f7fUhiYhEibCGgZnNMLNVZrbWzG5rps1FZrbczJaZ2T/CWU9Txmf3AmDp1hKIiYHjfgCFS2H1q51diohIlwlbGJhZAPgjcDowFrjEzMYe0GYE8GPgWOfcOODmcNXTnGF9komPjWFpQam34LCvQ+8h8O5vtHcgIlEjnHsGU4G1zrn1zrlaYBZw4NVdrgH+6JzbDeCc2xHGepoUG4hhzIA0lhaUeAsCQTjhh7D1M1jzemeXIyLSJcIZBtnAlkbP8/1ljY0ERprZh2b2sZnNaOqNzOxaM1tgZgvae/hoW4zPTmP51lJCe6+JfMQl3t7BnF9r70BEokJXDyDHAiOA6cAlwCNm1vvARs65h51zk51zk/v06dPhRYwf2Iuymno276r0FgSCcMKt3t7B6tc6/PNERLqbcIZBAZDT6Pkgf1lj+cALzrk659wGYDVeOHSqLwwi73XExZCeq70DEYkK4QyD+cAIM8szszjgYuCFA9o8h7dXgJll4XUbrQ9jTU0a0S+FYMD2DyLD/r2DbYt0ZJGIRLywhYFzrh64AXgNWAE85ZxbZmZ3mNnZfrPXgGIzWw68A9zqnOv02eLiYwOM7JfKssZ7BgCHz9TegYhEhbBOR+Gcexl4+YBl/9PosQN+4N+61PiBvXh9+Xacc5iZtzAQhBP+E57/Hqx6BUaf0bVFioiESVcPIHcb47PT2F1Zx9aSAy5af/hMSM/T3oGIRDSFgW/c3kHkggO6igKx3tjB9sWw6uUmXiki0vMpDHxj+qcRY7DswDAA7R2ISMRTGPgS4wIM75vC0q2lX14ZiIUT/xO2L9HegYhEJIVBI+MH9vpyN9Feh10EGUO1dyAiEUlh0Mi47F7sKKthR2n1l1cGYr0ji7YvgZUvdX5xIiJhpDBoZPzANACWNdVVBHDYhZAxDObcCaHuea1kEZGDoTBoZKwfBs12Fe0dOyhcAqu0dyAikUNh0EhqQpC8rOQvzlF0oPFf9/cOfqO9AxGJGAqDA4wbmPbFOYoOFIiFE3/k7R2s/HfnFSYiEkYKgwOMz+5FwZ4qdlfUttDoAsgc7l0NTXsHIhIBFAYHGD/QOxO52UFkaLR3sBRWvthJlYmIhI/C4ADj/EHkxQV7Wm64d+9AYwciEgEUBgdIT45jfHYaz3+2FdfSyWUxAe+8gx3LdK1kEenxFAZNuOyoIawqLGP+xt0tNxx/PvTKgQ/v6ZS6RETCRWHQhHMmZJOWEMvjcze23DAQhKNvgM1zYfO8TqlNRCQcFAZNSIwLcOHkHF5dur3pqSkaO/JySEyHD//QOcWJiISBwqAZl00bQn3IMWv+lpYbxiXD1Gu9M5KLVnVOcSIiHUxh0Iy8rGSOH5HFP+Ztpr6hlaOFpl4LsYnw0b2dU5yISAdTGLTgm0fnsr20mjeWF7bcMDkLJl4Gn/8TSrd2TnEiIh1IYdCCk0f3Jbt3Io/P3dR642NuANcAHz8Q/sJERDqYwqAFgRjj0qMGM3d9MWt3lLXcOD0Xxp0HC/4CVXs6ozwRkQ6jMGjFxVNyiAvE8Le27B0cexPUlsGCR8NfmIhIB1IYtCIzJZ4zDx/AMwsLKK+pb7nxgCNg6Ekw70Goa+WQVBGRbkRh0AaXHz2E8pp6Zn9W0Hrj426G8kJYPCvsdYmIdBSFQRtMzOnNuIFp/H3uppbnKwLIOxEGTICP7oNQQ6fUJyJyqBQGbWBmfPNob76iTzbsaq2xN3ZQvBZW6tKYItIzKAza6Owj/PmKPm7DQPLYc7yjiz68B1rbkxAR6QYUBm20d76i19oyX1FMAI75Dyj4FDZ92DkFiogcAoVBO+ydr+jJT1qZrwhgwjcguQ98cE/Y6xIROVQKg3bIy0rmhJF9+Mcnm6hrbb6iYCIc9R1Y+wZsX9o5BYqIHCSFQTt9c9oQCktrWp+vCGDytyGYrAnsRKTbUxi000n75iva2HrjpAyYdCUseRr2bA53aSIiB01h0E6BGOMb0wbz8fpdrClsZb4igKO/5x1uOvf+8BcnInKQFAYHYeZkf76ithxm2msQHHYhLHwMKls5R0FEpIsoDA7C3vmKnm3LfEUAx9wIdZXwycPhL05E5CCENQzMbIaZrTKztWZ2WxPrrzSzIjNb5N+uDmc9HWnffEUL81tv3G8sjDzdm8Cupjz8xYmItFPYwsDMAsAfgdOBscAlZja2iab/dM5N8G9/Clc9HW1iTm/GZ6fx+NxNhEJtOMv4hB9C1W5Nby0i3VI49wymAmudc+udc7XALOCcMH5epzIzvn1cHmt2lLdtNtNBk2HodG8Cu7qqsNcnItIe4QyDbKDxqbr5/rIDXWBmi83saTPLaeqNzOxaM1tgZguKiorCUetBOeeIbCbk9ObXr6ykrLqu9ReccCtU7IDP/h7+4kRE2qGrB5BfBHKdc4cDbwCPNdXIOfewc26yc25ynz59OrXAlsTEGD8/exzFFTX84c01rb9gyLGQM82boqK+Nuz1iYi0VTjDoABo/Jf+IH/ZPs65Yudcjf/0T8CkMNYTFkfk9Gbm5Bz++tHG1s87MPP2DkrzYfE/O6dAEZE2CGcYzAdGmFmemcUBFwMvNG5gZgMaPT0bWBHGesLm1q+OIikuwO0vLmv94jfDT/EufvPB3dDQhsNSRUQ6QdjCwDlXD9wAvIb3I/+Uc26Zmd1hZmf7zW40s2Vm9jlwI3BluOoJp8yUeG45bRQfri3m1aXbW25s5h1ZtGs9LJvdOQWKiLTCWv1LtpuZPHmyW7BgQVeX8SX1DSG+dt8HlFXX8+YPTiQxLtB841AIHjjGe3zdRxDT1UM3IhLpzOxT59zk5tbrV6iDxAZi+PnZ4yjYU8UDc9a23DgmBo6/BYpWwCpdGlNEup7CoAMdNTSTs48YyIPvrWdzcWXLjcedB+l58N5dujSmiHQ5hUEH+8kZY4iNMe749/KWGwZi4fgfwLZFsPatTqlNRKQ5CoMO1r9XAv9x8gjeXFHInFU7Wm58+MWQNgje+532DkSkSykMwuCq43IZmpXMz19cTk19Q/MNY+Pg2Jtgy8ew6cPOK1BE5AAKgzCIjw3wP2eNZcPOCh79YGPLjY+8HJL7emMHIiJdRGEQJtNH9eXUsf247+01bC+pbr5hMBGOvh7WvwP5n3ZegSIijbQpDMzsJjNLM8+fzWyhmZ0W7uJ6up+eOZb6kONXL7dyYvWUb0NCb3hfewci0jXaumdwlXOuFDgNSAcuB+4MW1URYnBmEt89cRgvfL6VeeuLm28YnwrTroNVL8P2pZ1XoIiIr61hYP79GcDfnHPLGi2TFlx34jCyeyfysxeWUd8Qar7h1GshLhXe/9/OK05ExNfWMPjUzF7HC4PXzCwVaOGXTfZKjAvw06+NYeX2Mp78ZHPzDZMyvO6iZbNhZxumwxYR6UBtDYNvA7cBU5xzlUAQ+FbYqoowXx3Xn6PyMvjDW2uprG1hptKjb4DYBPjg951XnIgIbQ+Do4FVzrk9ZnYZ8N9ASfjKiixmxn/OGMXO8hoe+2hT8w1T+sCkK+HzWVC0qtPqExFpaxg8AFSa2RHALcA64PGwVRWBJg3J4KRRfXjw3XWUVLVwicwTfghxKfDqj3VWsoh0mraGQb3z5ro+B/g/59wfgdTwlRWZbjltFCVVdfz5/fXNN0rOguk/gnVvwZrXO684EYlqbQ2DMjP7Md4hpS+ZWQzeuIG0w/jsXpx52AD+/MEGistrmm845RrIHOHtHehaySLSCdoaBjOBGrzzDbbjXc/4d2GrKoJ9/9SRVNU18MCcdc03io2DGb+GXevgk4c6rzgRiVptCgM/AJ4AepnZ14Bq55zGDA7C8L4pnH/kIB7/eBPbSqqabzjiVBhxGrz7WyhvZfZTEZFD1NbpKC4CPgEuBC4C5pnZ18NZWCS76ZQROOe47+1Wroj21V9BXSW8/f86pzARiVpt7Sb6L7xzDK5wzn0TmAr8NHxlRbacjCQumTqYp+ZvYVNxRfMNs0bAUd+FhX+DrYs6rT4RiT5tDYMY51zjvoridrxWmnDDScOJDRj3vNnK2cYn3ApJmfDqbTrUVETCpq0/6K+a2WtmdqWZXQm8BLwcvrIiX9+0BK44JpfnFhWwurCs+YaJveGUn8LmubDs2U6rT0SiS1sHkG8FHgYO928PO+d+FM7CosF3TxhGSlws//t6K2cbT7wc+h8Gr/8P1FZ2TnEiElXa3NXjnHvGOfcD/zY7nEVFi/TkOK4+fiivLSvk8y17mm8YE4AZv4HSfPjo3k6rT0SiR4thYGZlZlbaxK3MzEo7q8hIdtVxuaQnBbmrtb2D3GNh3HnwwT2wZ0un1CYi0aPFMHDOpTrn0pq4pTrn0jqryEiWmhDkuunDeH/NTj5u6QI4AKf+P8DBmz/rlNpEJHroiKBu4JtH59IvLZ67XluFa+mIod45cOzNsPQZ2PRRp9UnIpFPYdANJAQD3HDyCBZs2s2c1UUtNz72JkjLhld+BKGGzilQRCKewqCbmDk5h5yMRO56bRWhUAt7B3FJcOodsH0xLHqi8woUkYimMOgm4mJjuPmUkSzbWsqry7a33Hj8BZAzDd66A6p1jSEROXQKg27k3InZDO+bwp2vrGTBxl3NNzSD0++Eip3wluYtEpFDpzDoRgIxxh3njKO8pp6vPziXix6ay7uri5oeVB440Zu3aP4jsO6dzi9WRCKKtXj0Sjc0efJkt2DBgq4uI6wqa+uZ9ckWHn5vPdtLqxmfncb104fz1XH9iYmx/Q3rquChE6C2Aq77yJu6QkSkCWb2qXNucnPrtWfQDSXFxXLVcXm8958n8ZsLDqO8up7rnljIqb9/l2c+zaeuIeQ1DCbCeQ9C2XZvIjsRkYOkMOjG4mJjmDllMG/dMp37LplIMBDDLf/6nOm/m8Pf5m6kuq4BsifBCT+Ez5+E5S90dcki0kOpm6gHcc7xzqod/N/ba1m4eQ9ZKfFcecwQLp08kIwnT4eSfPjex5DSt6tLFZFupku7icxshpmtMrO1ZtZsP4aZXWBmzsyaLVTAzDh5dD+eue4YZl07jbED07jr9dUc/dv3uDvlFkI15fDizbrugYi0W9jCwMwCwB+B04GxwCVmNraJdqnATcC8cNUSacyMaUMzefyqqbzx/RO4YNIgHl4Zxy+rvw6rXmL5Kw+2fOKaiMgBwrlnMBVY65xb75yrBWYB5zTR7v8BvwGqw1hLxBrRL5VfnXcYc287hcyv3MxCG0fOvJ9z6V3/4vG5G6moqe/qEkWkBwhnGGQDjedazveX7WNmRwI5zrmXWnojM7vWzBaY2YKiolbm7olS6clxfO+kkRx2/RMkBo2f1N3Hz55fwrRfv8UvX1pO/m5dFEdEmtdlRxOZWQxwN3BLa22dcw875yY75yb36dMn/MX1YMGsPGLP+A2H1y3mvRNXM31UXx79cCOn/f49lhZo6goRaVo4w6AAyGn0fJC/bK9UYDwwx8w2AtOAFzSI3AEmXg4jZ5Dz6W+57yvJzPnhdHonBrn6sQXsKFVvnIh8WTjDYD4wwszyzCwOuBjYdyC8c67EOZflnMt1zuUCHwNnO+ei87jRjmQGZ90LwSSYfS05vYL86YoplFbXcc3jC7zzE0REGglbGDjn6oEbgNeAFcBTzrllZnaHmZ0drs8VX2o/+NrvYetn8P7djB2Yxh8unsjighJufXpxyxfREZGoExvON3fOvQy8fMCy/2mm7fRw1hKVxp0LKy+C934LI0/j1LET+dGM0dz5ykpG9E3hxlNGdHWFItJNaDqKSHfGbyG5LzxzDVTs5DsnDOX8I7O5+43VvLR4W1dXJyLdhMIg0iWmwwWPeFNV/OV0rLSAX59/GJOHpHPLvxaxOH9PV1coIt2AwiAa5B4Hl8/2Zjd9dAbxezbw4OWTyEyO55rHF7C9REcYiUQ7hUG0GHI0XPlv7xoIf5lBVtkq/nzlZMqr67nm8QVU1eoII5FopjCIJgOOgKtehUA8/PVrjK5dzr2XTGTp1hJu+dcizWckEsUUBtEma4QXCCl94PFzOSV2CT85fQwvL9nOPW+t6erqRKSLKAyiUe8c+NarkDUcnryYqzM+56LJg7j3rTU8v6ig9deLSMTRxW2iWXUJ/GMmbJlH/Rm/59KFo1i0ZQ/nHDGQ6voQVbUNVNc1UFXX8MXH/vPeSUF+NGM0503Mxsxa/zwR6TKtXdxGYRDtaivhqW/C2jeoPPF2vrnyKAr2VJEYDJAQDJAYFzjgcYz3PC7AvPW7WLRlD0flZfCLc8czol9qV2+NiDRDYSCtq6+F2d+BZc/C8bfAyT/15jdqRSjkmDV/C795dSUVNfVcffxQbjxlOElxYT2xXUQOQpde9lJ6iNg4uOBPMOlKeP9/4emroHJXqy+LiTEuPWowb99yIudOzObBd9dx6t3v8cbywvDXLCIdSnsGsp9z8MHd8M6vILkPnPNHGH5Km1/+yYZd/PdzS1hdWM5XxvTlZ2eNIycjqZWPdOwoq2FpQQlLC0ppCIX41rF5pCfHHerWiEgj6iaS9tu6yOs2KloJU66BU38OccltemldQ4hHP9jAPW+uweH4j5NHcM3xQ4mLjcE5R/7uKpZt9X74l/r3O8trAK9nyoDUhCA/PG0klx41hECMBqZFOoLCQA5OXTW8dQd8/EfIGAbnPwyD2n7doYI9Vdzx4jJeW1bI0D7J9E9LYNnWUkqq6gAIxBgj+qYwPrsX4wamMT67F2MGpFGwu4rbX1jG3PXFjBmQxs/PHsfUvIxwbaVI1FAYyKHZ8B489z0oLfAGl0/8EQSCbX752ysL+d1rq4kLGGMH9mJ8dhrjB/ZiVP9UEoKBJl/jnOPlJdv55UvL2VpSzTkTBvLj08fQv1dCR22VSNRRGMihqy6BV26Dz//hTWlx3sPQd3TYP7aytp4H5qzjoffWExtj/MfJI7jquFziY5sOERFpno4mkkOX0AvOewBm/t2bCvuhE2Du/RAKhfVjk+JiueW0Ubz5/RM5ZlgWv3l1JTPueZ85q3aE9XNFopHCQNpuzFlw3VwYdhK89mP465mw9k3vKKQwGpyZxJ+umMxfvzUFA678y3yufmwBW/dUhfVzRaKJuomk/ZyDz/4Gb/8Cyguhz2iYdh0cPhOCiWH96Nr6EH/5cAP3vrWGhGCA+79xJEcNzQzrZ4pEAo0ZSPjU18DSZ70jjrYvgaRMmHwVTLkaUvuH9aPXFZVzzWML2LyrktvPHsdl04aE9fNEejqFgYSfc7DxA/j4flj1CsTEwvgL4OjveQPOYVJSVcfNsz7jnVVFXHrUYG4/axxxser5FGmKwkA6V/E6mPcQfPZ3qKuAIcd5oTByBsR0/FFADSHHXa+v4oE565iSm84Dl00iKyW+wz9HpKdTGEjXqNoDCx+HTx6Gki1eF9Ko02H0WTB0OgQ79pyB5xcV8KNnFpORFMfD35zM+OxeHfr+Ij2dwkC6VkM9rHoZlj8Pa16HmlKIS4HhX/GOThpxGiSkdchHLS0o4drHF7Crspbffv0Izj5iYIe8r0gkUBhI91FfAxveh5UvwsqXoWIHxARh6Ikw+msw+kxI6XtIH7GzvIbr/v4p8zfu5rrpw/jhaaM0v5EICgPprkINkD8fVrwIK/8NuzcCBtmTIGeqd589CdJz23RthcZq60Pc/uIy/jFvMyeN6sMfLplIWkLbp9AQiUQKA+n+nIPCZV4orHsbtn0O9dXeuqTM/cGQPRmyj4Sktk1c9/ePN3H7C8vISI7jxJF9mJqXwVF5meRkJOoynRJ1FAbS8zTUwY7lUPAp5H/q3RetBPz/VjOGeuEwaKq3F9FvPASavrra/I27ePi99czfuIs9ld6Mqf3TEpial+GHQwbD+6YoHCTiKQwkMlSXwrZFfkAs8O7Ltnnrgkn7u5dyjoJBU7609xAKOdYWlTNvwy4+2bCLeeuL2VHmXUchIzmOKbnpTM3LZHT/VAZnJDGwd6LGGiSiKAwkMjnnTZq3ZZ439rBlHmxbDK7BW585wguGnKle11LGMIhLavRyx6biSi8YNuzik43FbNm1f66jYMAYlJ7E4IwkhmTuvU/e97i56bdFuiuFgUSP2grY+pkXDFv8gKhqdC3n1AFeF1NGnn/v39LzICGN7SXVrC8qZ9OuSjYVV7J5V4V3X1xJWU39Fz5qeN8Urj4uj/OPHKSznqVHUBhI9HLOOyN62yLYvQF2bYBd671beeEX2yZlecGQOczbi8gc6t8Pw8WlsLuyjk3FFWz2g+KN5YUsKShhQK8EvnPCUC6eOlh7C9KtKQxEmlJT7h3OujccGt9KC77YNrmvFxL7gmIYLmMY7+/uzX3vbmb+xt1kpcRx9fFDuWzaEFLimx7MFulKCgOR9qqt9INhnbdnsWsdFPvPG+9RWAAyh7EraSjv7snizZ0ZbIvL5cSjj+aK44fTOymu67ZB5AAKA5GOVFPmBcXONbBjhXfI644VXjeU8678VucCbGIAdZmjGDzqSJKzx0LWSG/PIszXexBpTmthoP1ZkfaIT/Wm5T5wau66Kti5GnaspHTj51St/oy04iUkz31rX5MQRlFMX7YFB1EYzKEofjA74wezMzGX6vg+DMlM5urjh5IYp7EH6Xxh3TMwsxnAH4AA8Cfn3J0HrP8ucD3QAJQD1zrnlrf0ntozkJ5iw84KnvxgBbZrPZnVm+hbs5m+tZvpX5fPgPp8Eqne17aCRLaEsiA2gUF9M0hJTobYRIiN9/YmYuMhNsG7BRO9OZx6D4beQ6DXIG+9SAu6rJvIzALAauBUIB+YD1zS+MfezNKcc6X+47OB7znnZrT0vgoDiQjOQelWKF7jdTntXEPxtg2szi/CGmoYnBZD/2SIqa/2Jvirq/Lu66sgVP/l90sdAL1y/IAYDL39x71yvKvOxae1e44niSxd2U00FVjrnFvvFzILOAfYFwZ7g8CXzL75BkQinBn0yvZuQ6cDkAmMq67j5y8s55mF+YyLS+PuiyYwqn/qF1/bUOedfb1nc6PbFtizyTsBb/lzXw6MYBKk9PNCI9W/b/w8pb931nZCb4jVwHc0CueewdeBGc65q/3nlwNHOeduOKDd9cAPgDjgZOfcmibe61rgWoDBgwdP2rRpU1hqFukuXlu2nZ88u4Sy6npuOW0kVx8/tO3TY4Qa9odFST6UbfeOgirbBmV777d7V6JrSjDJC4XE3k3fJ2VAchYk99l/S+gNMTr5rjvrym6iNoVBo/aXAl91zl3R0vuqm0iixc7yGv5r9hJeW1bIlNx07rrwCIZkJnfcB9SU7Q+H8kKo2u1doa56z5fvq0u8x7VlTb9XTKx34l5yny8GRUYeZI3wjqZKHaCuqi7Uld1EBUBOo+eD/GXNmQU8EMZ6RHqUrJR4HrxsEs8uLOD2F5Zx+h/e57/OHMOlUwc3O8tqKOQoqaqjuKKGneW1OAcj+6WQ2dR1oeNTvVvW8LYX1VDvhUZFUTO3nVC+wz/Le4c3xrFXXApkDveCIWvk/pDIGNrhl0GV9gtnGMwHRphZHl4IXAxc2riBmY1o1C10JvClLiKRaGZmXDBpEEcPy+TWpz/nv2Yv5bVlhUzNTWdneS3FFbXsqqihuLyWneW17K6spSH05b39rJR4xgxIZVS/VEb1T2XMgDSG901p/xQagVhI6ePdWuOc1x21c7V/W+Pdb54LS55qtJEx3l6FtbGbKS7Z77Lq5XVPJfTa34W173EviO/lTU4YTPJeE0zyjsTS3kmTwn1o6RnAPXiHlj7qnPulmd0BLHDOvWBmfwC+AtQBu4EbnHPLWnpPdRNJtAqFHH/7eBO/fmUF1XUhUuNjyUyJIyM5jsyUeLJS4shMjvefx5GVEk/IOVZtL2PV9jJWbi9jdWEZNfXeyXExBrlZyYzpn8bo/qmcMqYfYwd2zPWoW1VbAcVr9wdE2fY2vtB5U4lUlzTqxvIfN3WU1ZfY/mCIS4JgsncfiPO6ugJB71KsgVj/Prj/PhD0zjp3Dd4JhiH/vvGt8bJ9hwUnevfBBO9zY/37vc8txvv3qK2AukqoLfef+4/rKv3n5TDtezDq9IP6J9cZyCIRprrOm6b7YCbGawg5NhZXeOGwrZSV28tYVVjGpuJKAA4f1IuZU3I4+4iBpPakS4U65/1oNh7jqC71BslrK/f/oNZV+s8PWN5QB6G6Rvf1+583XudC3o93TMC7txgvIPY9Nm8dBg213iHBdVVed5l/hnrb+KG1L7hSvNA65kYY87WD+idSGIhIq3ZX1PLcogJmfbKFVYVlJAYDnHn4AC6eksOkIem6Etyhcs4Lk7pK75KudZVQV+0FhQv5P/z+j36YurMUBiLSZs45Ps8v4Z/zN/PCoq1U1DYwrE8yF08ZzPlHZjc9EC09gsJARA5KRU09Ly3exqz5m1m4eQ/BgHHq2H6cOrYfwUAMhu3749XY+4est8AMAmZMHNxbAdJNKAxE5JCtLizjn/O38OzCfHZX1rX5dbExxgkj+3DOhIGcNra/JuHrQgoDEekwNfUNbC6uxOF1gwM4HM55z50/o4xz3kD3myt28MKiAraWVJMcF+Cr4/pz7sRsjhmWSWxAZyx3JoWBiHSpUMjxycZdPPdZAS8t2UZZdT19UuM56/CBnDcxm/HZaRqg7gQKAxHpNqrrGpizagezPyvgnZVF1DaEGNonmfMmZHPuxGxyMpK6usSIpTAQkW6ppLKOl5duY/ZnBXyyYRcAk4ekc+7EbM48bADpyQc3e2oo5Fi9o4y6eqe9jkYUBiLS7eXvruSFz7cye2EBa3aUEwwY00f15byJ2Zw8um+LJ9jVN4RYtrWUTzbsYt6GXczfuIuSKm+Qe+Lg3lx34jC+MqYfMW2d9TVCKQxEpMdwzrF8WynPfVbA84u2sqOshtT4WM44bADnTszmqLwMahtCLM4v4ZMNxczbsIuFm3ZTUeudlZ2bmcTUvAym5mVSWVvPI++vZ8uuKob3TeE7JwzlnAnZxMVG58C1wkBEeqSGkGPuumJmf1bAq0u3UVHbQFZKPKXVddT68yuN7p/q//hnMDU3g75pX5z9tL4hxEtLtvHAnHWs3F7GgF4JXH38UC6ekkNyfHRdAl5hICI9XlVtA2+sKOSN5YX0T4tnal4mk4ekt3lcwTnHnNVFPDhnHfM27KJ3UpBvHp3LlcfkknGQYxM9jcJARKSRTzft5sF31/HG8kISgjHMnJxDblYytfUh6hpC1NaHqGkIUVfvqG1o8O9D1DaEyM1M4sZTRhAf2/NOnlMYiIg0YU1hGQ+9t57nPiug/oBrQMTFxhAXiCEuNoZgwLz7mBjW76xgSm46D10+ucftUSgMRERaUF5TT119yAuA2BhiY6zZw1Ff/HwrP/zX5/RNi+fRK6Ywol9qJ1d78FoLg+gcVhcR8aXEx5KeHEdyfKw3AV8L5yWcdcRAZl07jaraEOff/xHvri7qxErDS2EgItIOEwen8/wNx5KdnshVf53P43M3dnVJHUJhICLSTtm9E3n6umM4aVQf/uf5Zfzs+aXUN7TnSmbeEU5L8kt4dek2NuysINTEtas7U3QdaCsi0kFS4mN56PLJ3PnKCh55fwMbiiv5v0snktbC5UL3nlT30uJtvLRk277LjQIkxwUYMyCNsQPTGOvfj+yXelCXNz0YGkAWETlEsz7ZzH8/t5S8rGT+fMUUBmfun3DPOcfqwnL+vXgrLy3exvqdFQRijGOGZXLW4QMZ2T+V1dvLWLa1hOXbSlmxrYzymnoAAjHG8D4p+wLipNF9Gd435aBqbG0AWXsGIiKH6OKpgxmcmcR1f1/Iufd/yEOXTyI9Kci/F2/j34u3sXZHOTEGRw/L5OrjhzJjfP8vHJo6Iac3kAN4E+1t2V3J8q2lLN9WyvKtpXy83jsTOy0x9qDDoDXaMxAR6SAbdlbw7b/OZ0NxBc55l/88Ki+DMw8fyIxx/emTevCXAN1VUUswYKS20A3VEu0ZiIh0krysZGZ/71juf3ctA3slcvr4/l+aL+lghfskN4WBiEgH6pUU5Menj+nqMtpNh5aKiIjCQEREFAYiIoLCQEREUBiIiAgKAxERQWEgIiIoDEREhB44HYWZFQGbDvLlWcDODiynO4i0bYq07YHI26ZI2x6IvG1qanuGOOf6NPeCHhcGh8LMFrQ0N0dPFGnbFGnbA5G3TZG2PRB523Qw26NuIhERURiIiEj0hcHDXV1AGETaNkXa9kDkbVOkbQ9E3ja1e3uiasxARESaFm17BiIi0gSFgYiIRE8YmNkMM1tlZmvN7LaurudQmdlGM1tiZovMrEdeB9TMHjWzHWa2tNGyDDN7w8zW+PfpXVljezSzPbebWYH/PS0yszO6ssb2MrMcM3vHzJab2TIzu8lf3iO/pxa2p8d+T2aWYGafmNnn/jb93F+eZ2bz/N+8f5pZi5dKi4oxAzMLAKuBU4F8YD5wiXNueZcWdgjMbCMw2TnXY0+UMbMTgHLgcefceH/Zb4Fdzrk7/dBOd879qCvrbKtmtud2oNw5d1dX1nawzGwAMMA5t9DMUoFPgXOBK+mB31ML23MRPfR7MjMDkp1z5WYWBD4AbgJ+ADzrnJtlZg8CnzvnHmjufaJlz2AqsNY5t945VwvMAs7p4pqinnPuPWDXAYvPAR7zHz+G9z9qj9DM9vRozrltzrmF/uMyYAWQTQ/9nlrYnh7Lecr9p0H/5oCTgaf95a1+R9ESBtnAlkbP8+nh/wHgfdmvm9mnZnZtVxfTgfo557b5j7cD/bqymA5yg5kt9ruRekR3SlPMLBeYCMwjAr6nA7YHevD3ZGYBM1sE7ADeANYBe5xz9X6TVn/zoiUMItFxzrkjgdOB6/0uiojivD7Mnt6P+QAwDJgAbAP+t0urOUhmlgI8A9zsnCttvK4nfk9NbE+P/p6ccw3OuQnAILyekNHtfY9oCYMCIKfR80H+sh7LOVfg3+8AZuP9BxAJCv1+3b39uzu6uJ5D4pwr9P9HDQGP0AO/J78f+hngCefcs/7iHvs9NbU9kfA9ATjn9gDvAEcDvc0s1l/V6m9etITBfGCEP7oeB1wMvNDFNR00M0v2B78ws2TgNGBpy6/qMV4ArvAfXwE834W1HLK9P5i+8+hh35M/OPlnYIVz7u5Gq3rk99Tc9vTk78nM+phZb/9xIt6BMivwQuHrfrNWv6OoOJoIwD9U7B4gADzqnPtl11Z08MxsKN7eAEAs8I+euD1m9iQwHW+63ULgZ8BzwFPAYLypyi9yzvWIQdlmtmc6XteDAzYC32nU197tmdlxwPvAEiDkL/4JXj97j/ueWtieS+ih35OZHY43QBzA+wP/KefcHf7vxCwgA/gMuMw5V9Ps+0RLGIiISPOipZtIRERaoDAQERGFgYiIKAxERASFgYiIoDAQ6VRmNt3M/t3VdYgcSGEgIiIKA5GmmNll/hzxi8zsIX8isHIz+70/Z/xbZtbHbzvBzD72JzmbvXeSMzMbbmZv+vPMLzSzYf7bp5jZ02a20sye8M+KFelSCgORA5jZGGAmcKw/+VcD8A0gGVjgnBsHvIt3hjHA48CPnHOH453Zunf5E8AfnXNHAMfgTYAG3kyZNwNjgaHAsWHeJJFWxbbeRCTqnAJMAub7f7Qn4k3EFgL+6bf5O/CsmfUCejvn3vWXPwb8y587Kts5NxvAOVcN4L/fJ865fP/5IiAX74IkIl1GYSDyZQY85pz78RcWmv30gHYHO5dL4/lhGtD/h9INqJtI5MveAr5uZn1h3/V+h+D9/7J3FshLgQ+ccyXAbjM73l9+OfCufxWtfDM713+PeDNL6syNEGkP/UUicgDn3HIz+2+8K8nFAHXA9UAFMNVftwNvXAG86YEf9H/s1wPf8pdfDjxkZnf473FhJ26GSLto1lKRNjKzcudcSlfXIRIO6iYSERHtGYiIiPYMREQEhYGIiKAwEBERFAYiIoLCQEREgP8P7DN1dS6OnxMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(historys[4]['loss'])\n",
    "plt.plot(historys[4]['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6003360748291016,\n",
       " 0.39249658584594727,\n",
       " 0.27260082960128784,\n",
       " 0.20907080173492432,\n",
       " 0.16259503364562988,\n",
       " 0.09351905435323715,\n",
       " 0.10405447334051132,\n",
       " 0.08963260799646378,\n",
       " 0.21900108456611633,\n",
       " 0.15422195196151733,\n",
       " 0.07747237384319305,\n",
       " 0.038994014263153076,\n",
       " 0.03818773105740547,\n",
       " 0.04631568491458893,\n",
       " 0.03413725271821022,\n",
       " 0.034633006900548935,\n",
       " 0.03465097397565842,\n",
       " 0.06722856312990189,\n",
       " 0.06923086941242218,\n",
       " 0.042484212666749954,\n",
       " 0.024996832013130188,\n",
       " 0.018310630694031715,\n",
       " 0.008238214068114758,\n",
       " 0.009727055206894875,\n",
       " 0.014016089029610157,\n",
       " 0.0065970211289823055,\n",
       " 0.005025025922805071,\n",
       " 0.005692292470484972,\n",
       " 0.00446320790797472,\n",
       " 0.005189503077417612]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historys[4]['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6843299865722656,\n",
       " 0.8011519312858582,\n",
       " 0.8471583724021912,\n",
       " 1.1897672414779663,\n",
       " 1.2004234790802002,\n",
       " 1.1957978010177612,\n",
       " 0.788483202457428,\n",
       " 1.1862387657165527,\n",
       " 0.5186746716499329,\n",
       " 0.6088327765464783,\n",
       " 0.7353946566581726,\n",
       " 0.7120090126991272,\n",
       " 0.8727397322654724,\n",
       " 0.7315264940261841,\n",
       " 0.7599920630455017,\n",
       " 0.8403003811836243,\n",
       " 0.8989680409431458,\n",
       " 0.7093985080718994,\n",
       " 0.8587856292724609,\n",
       " 0.7403738498687744,\n",
       " 0.8611348867416382,\n",
       " 0.7187201976776123,\n",
       " 0.8760604858398438,\n",
       " 0.908010721206665,\n",
       " 0.840823233127594,\n",
       " 0.8675487637519836,\n",
       " 0.9062723517417908,\n",
       " 0.9102680683135986,\n",
       " 0.9496763944625854,\n",
       " 0.9356536865234375]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historys[4]['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3442 2511\n"
     ]
    }
   ],
   "source": [
    "cough=0\n",
    "nocough=0\n",
    "for i in sup_DATA[1]['LABELS']:\n",
    "    if i == 1:\n",
    "        cough+=1\n",
    "    else:\n",
    "        nocough+=10\n",
    "print(cough,nocough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_samples: 288\n",
      "acc:  0.9097222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_samples: 288\n",
      "acc:  0.8854166666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_samples: 288\n",
      "acc:  0.9236111111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate ROC curves for each run\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "import sklearn\n",
    "\n",
    "# EDIT MODEL PATHS TO USE\n",
    "models = {0: './model_1/0/*.hdf5',\n",
    "          1: './model_1/1/*.hdf5',\n",
    "          2: './model_1/2/*.hdf5',\n",
    "          3: './model_1/3/*.hdf5',\n",
    "          4: './model_1/4/*.hdf5'\n",
    "          }\n",
    "\n",
    "tprs = []\n",
    "base_fpr = np.linspace(0, 1, 101)\n",
    "for iii in range(3):\n",
    "    test_imgs    = sup_DATA[iii]['MEL'][ int(0.7*sup_data_size): int(0.85*sup_data_size)]\n",
    "    test_labels  = sup_DATA[iii]['LABELS'][ int(0.7*sup_data_size): int(0.85*sup_data_size)]\n",
    "    TEST         = specGenerator(test_imgs,test_labels,batch_size=48,target_size=(64,64))\n",
    "    path = './model_1/0'\n",
    "#     for file in os.listdir(path):\n",
    "#         model_path = path+'/'+file\n",
    "#         model_path = path+'/'+file\n",
    "    model = keras.models.load_model(\"./supervised_2000_1D/4/030--0.285--0.249.hdf5\")\n",
    "    y_score = model.predict(TEST)\n",
    "    fpr, tpr, _ = roc_curve(test_labels[:len(y_score)], y_score)\n",
    "    print('Num_samples:', len(y_score))\n",
    "    print('acc: ', sklearn.metrics.accuracy_score(test_labels[:len(y_score)], y_score>0.7))\n",
    "\n",
    "    plt.plot(fpr, tpr, 'b', alpha=0.15)\n",
    "    tpr = interp(base_fpr, fpr, tpr)\n",
    "    tpr[0] = 0.0\n",
    "    tprs.append(tpr)\n",
    "\n",
    "tprs = np.array(tprs)\n",
    "mean_tprs = tprs.mean(axis=0)\n",
    "std = tprs.std(axis=0)\n",
    "\n",
    "tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "tprs_lower = mean_tprs - std\n",
    "\n",
    "plt.plot(base_fpr, mean_tprs, 'b')\n",
    "plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "plt.savefig('roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[105  10]\n",
      " [ 10 163]]\n",
      "1\n",
      "[[115  14]\n",
      " [ 16 143]]\n",
      "2\n",
      "[[114   9]\n",
      " [ 10 155]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC curves for each run\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "import sklearn\n",
    "\n",
    "def to_one_or_zero(bool):\n",
    "    return 1 if bool else 0\n",
    "\n",
    "for iii in range(3):\n",
    "    print(iii)\n",
    "    test_imgs    = sup_DATA[iii]['MEL'][ int(0.7*sup_data_size): int(0.85*sup_data_size)]\n",
    "    test_labels  = sup_DATA[iii]['LABELS'][ int(0.7*sup_data_size): int(0.85*sup_data_size)]\n",
    "    TEST         = specGenerator(test_imgs,test_labels,batch_size=48,target_size=(64,64))\n",
    "#     for file in os.listdir(path):\n",
    "#         model_path = path+'/'+file\n",
    "#         model_path = path+'/'+file\n",
    "    model = keras.models.load_model(\"./supervised_2000_1D/4/030--0.285--0.249.hdf5\")\n",
    "    y_score = model.predict(TEST)\n",
    "    y_score = list(map(to_one_or_zero, y_score > .6))\n",
    " \n",
    "    con_mat = tf.math.confusion_matrix(labels=test_labels[:len(y_score)], predictions=y_score).numpy()\n",
    "    print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
